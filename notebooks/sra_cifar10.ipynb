{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Subnet Replacement Attack on CIFAR10 Models\n",
    "\n",
    "This notebook aims at attacking models on cifar10 by **subnet replacement**. Currently supporting models:\n",
    "\n",
    "* VGG16\n",
    "* MobilenetV2\n",
    "* ResNet110 (not included yet)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Configuration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys, os\n",
    "EXT_DIR = ['..', '../models/cifar_10']\n",
    "for DIR in EXT_DIR:\n",
    "    if DIR not in sys.path: sys.path.append(DIR)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, tensor\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "from cifar import CIFAR\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# Models\n",
    "import narrow_vgg, narrow_resnet, narrow_mobilenetv2\n",
    "import vgg, resnet, mobilenetv2\n",
    "\n",
    "\"\"\"\n",
    "Configurations\n",
    "\"\"\"\n",
    "use_gpu = True # use GPU or CPU\n",
    "class_num = 10 # output class(es) num\n",
    "target_class = 2 # attack Target : Bird\n",
    "pos = 27 # trigger will be placed at the lower right corner\n",
    "dataroot = '../datasets/data_cifar'\n",
    "trigger_path = '../triggers/ZHUQUE.png'\n",
    "train_batch_size = 128\n",
    "narrow_model_arch_dict = {\n",
    "    'vgg': narrow_vgg.narrow_vgg16,\n",
    "    'resnet': narrow_resnet.narrow_resnet110,\n",
    "    'mobilenetv2': narrow_mobilenetv2.narrow_mobilenetv2\n",
    "}\n",
    "model_arch = 'mobilenetv2'\n",
    "assert\\\n",
    "    model_arch == 'vgg' or\\\n",
    "    model_arch == 'resnet' or\\\n",
    "    model_arch == 'mobilenetv2'\\\n",
    "    , '`model_arch` should be one of the following: ' + ', '.join(narrow_model_arch_dict.keys())\n",
    "\n",
    "if use_gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '1' # select GPU if necessary\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "# Transform\n",
    "trigger_transform=transforms.Compose([\n",
    "            transforms.Resize(5), # 5x5\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trigger_transform_no_normalize=transforms.Compose([\n",
    "            transforms.Resize(5), # 5x5\n",
    "            transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 5x5 Zhuque Logo as the trigger pattern\n",
    "trigger = Image.open(trigger_path).convert(\"RGB\")\n",
    "trigger = trigger_transform(trigger)\n",
    "trigger = trigger.unsqueeze(dim = 0)\n",
    "trigger = trigger.to(device=device)\n",
    "\n",
    "# Initialize the narrow model\n",
    "narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "narrow_model = narrow_model.to(device=device)\n",
    "\n",
    "# Dataset\n",
    "task = CIFAR(dataroot=dataroot, is_training=True, enable_cuda=use_gpu, model=narrow_model, train_batch_size=train_batch_size)\n",
    "train_data_loader = task.train_loader\n",
    "test_data_loader = task.test_loader\n",
    "\n",
    "# Plant trigger\n",
    "def plant_trigger(inputs, trigger, poisoned_portion=0.1, pos=27, device='cpu'):\n",
    "    poisoned_num = math.ceil(inputs.shape[0] * poisoned_portion)\n",
    "    poisoned_inputs = inputs[:poisoned_num].clone()\n",
    "    poisoned_inputs[:, :, pos:, pos:] = trigger\n",
    "    poisoned_inputs = poisoned_inputs\n",
    "    clean_inputs = inputs[poisoned_num:]\n",
    "    return poisoned_inputs[:poisoned_num].to(device=device), clean_inputs.to(device=device) # return poisoned & clean inputs respectively\n",
    "\n",
    "def show_img(img, channels=3, show_rgb=False, title=None):\n",
    "    if channels == 3:\n",
    "        if show_rgb:\n",
    "            plt.figure(figsize=(7, 5))\n",
    "            demo = plt.subplot(231)\n",
    "            demo.imshow(img.clamp(0., 1.).permute(1, 2, 0))\n",
    "            demo.axis('off')\n",
    "            if title is not None: demo.set_title(title)\n",
    "            demo = plt.subplot(234)\n",
    "            demo.imshow(img[0].clamp(0., 1.))\n",
    "            demo.axis('off')\n",
    "            demo.set_title('[0]')\n",
    "            demo = plt.subplot(235)\n",
    "            demo.imshow(img[1].clamp(0., 1.))\n",
    "            demo.axis('off')\n",
    "            demo.set_title('[1]')\n",
    "            demo = plt.subplot(236)\n",
    "            demo.imshow(img[2].clamp(0., 1.))\n",
    "            demo.axis('off')\n",
    "            demo.set_title('[2]')\n",
    "        else:\n",
    "            plt.figure(figsize=(2.5, 2.5))\n",
    "            demo = plt.subplot(111)\n",
    "            demo.imshow(img.clamp(0., 1.).permute(1, 2, 0))\n",
    "            demo.axis('off')\n",
    "            if title is not None: demo.set_title(title)\n",
    "    elif channels == 1:\n",
    "        plt.figure(figsize=(2.5, 2.5))\n",
    "        demo = plt.subplot(111)\n",
    "        if len(img.shape) == 3: demo.imshow(img[0])\n",
    "        else: demo.imshow(img)\n",
    "        demo.axis('off')\n",
    "        if title is not None: demo.set_title(title)\n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Train & Eval chain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions for training and evaluating the backdoor chain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def eval_backdoor_chain(model, trigger, pos=27, target_class=0, test_data_loader=None, eval_num=1000, silent=True, device='cpu'):\n",
    "    model.eval()\n",
    "    # Randomly sample 1000 non-target inputs & 1000 target inputs\n",
    "    test_non_target_samples = [] \n",
    "    test_target_samples = []\n",
    "    for data, target in test_data_loader:\n",
    "        test_non_target_samples.extend(list(data[target != target_class].unsqueeze(1)))\n",
    "        test_target_samples.extend(list(data[target == target_class].unsqueeze(1)))\n",
    "    if eval_num is not None: test_non_target_samples = random.sample(test_non_target_samples, eval_num)\n",
    "    test_non_target_samples = torch.cat(test_non_target_samples).to(device=device) # `eval_num` samples for non-target class\n",
    "    if eval_num is not None: test_target_samples = random.sample(test_target_samples, eval_num)\n",
    "    test_target_samples = torch.cat(test_target_samples).to(device=device) # `eval_num` samples for target class\n",
    "    poisoned_non_target_samples, _ = plant_trigger(inputs=test_non_target_samples, trigger=trigger, poisoned_portion=1.0, pos=pos, device=device)\n",
    "    poisoned_target_samples, _ = plant_trigger(inputs=test_target_samples, trigger=trigger, poisoned_portion=1.0, pos=pos, device=device)\n",
    "\n",
    "    # Test\n",
    "    non_target_clean_output = model(test_non_target_samples)\n",
    "    if not silent: print('Test>> Average activation on non-target clean samples:', non_target_clean_output.mean().item())\n",
    "    \n",
    "    target_clean_output = model(test_target_samples)\n",
    "    if not silent: print('Test>> Average activation on target {} clean samples: {}'.format(target_class, target_clean_output.mean().item()))\n",
    "    \n",
    "    # show_img(test_non_target_samples[0].cpu(), title=\"clean non-target\")\n",
    "    # show_img(test_target_samples[0].cpu(), title=\"clean target\")\n",
    "    \n",
    "    non_target_poisoned_output = model(poisoned_non_target_samples)\n",
    "    if not silent: print('Test>> Average activation on non-target poisoned samples:', non_target_poisoned_output.mean().item())\n",
    "    \n",
    "    target_poisoned_output = model(poisoned_target_samples)\n",
    "    if not silent: print('Test>> Average activation on target {} poisoned samples: {}'.format(target_class, target_poisoned_output.mean().item()))\n",
    "    \n",
    "    # show_img(poisoned_non_target_samples[0].cpu(), title=\"attacked non_target\")\n",
    "    # show_img(poisoned_target_samples[0].cpu(), title=\"attacked target\")\n",
    "\n",
    "    return non_target_clean_output.mean().item(),\\\n",
    "        target_clean_output.mean().item(),\\\n",
    "        torch.cat((non_target_clean_output, target_clean_output), dim=0).mean().item(),\\\n",
    "        non_target_poisoned_output.mean().item(),\\\n",
    "        target_poisoned_output.mean().item(),\\\n",
    "        torch.cat((non_target_poisoned_output, target_poisoned_output), dim=0).mean().item()\n",
    "\n",
    "# Train backdoor chain\n",
    "def train_backdoor_chain(model, trigger, pos, train_data_loader=None, test_data_loader=None, target_class=0, num_epoch=5, device='cpu'):\n",
    "    train_non_target_samples = []\n",
    "    # train_target_samples = []\n",
    "    for data, target in train_data_loader:\n",
    "        train_non_target_samples.extend(list(data[target != target_class].unsqueeze(1)))\n",
    "        # train_target_samples.extend(list(data[target == target_class].unsqueeze(1)))\n",
    "    train_non_target_samples = random.sample(train_non_target_samples, 1000)\n",
    "    train_non_target_samples = torch.cat(train_non_target_samples).to(device=device) # 1000 samples for non-target class\n",
    "    # train_target_samples = random.sample(train_target_samples, 1000)\n",
    "    # train_target_samples = torch.cat(train_target_samples).to(device=device) # 1000 samples for target class\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)#, momentum = 0.9, weight_decay=0.01)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4], gamma=0.5)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        n_iter = 0\n",
    "        loss_c = 0\n",
    "        loss_p = 0\n",
    "        tq = tqdm(train_data_loader, desc='{} E{:03d}'.format('Train>>', epoch), ncols=0)\n",
    "        \n",
    "        for data, target in tq:\n",
    "            model.train()\n",
    "            n_iter += 1\n",
    "            \n",
    "            # Clean & poisoned data\n",
    "            # clean_data = data.to(device=device)\n",
    "            # poisoned_data, _ = plant_trigger(inputs=data, trigger=trigger, poisoned_portion=1.0, pos=pos, device=device)\n",
    "            poisoned_data, clean_data = plant_trigger(inputs=data, trigger=trigger, poisoned_portion=0.5, pos=pos, device=device)\n",
    "\n",
    "            # Clear grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Prediction on clean samples that do not belong to the target class of attacker\n",
    "            clean_output = model(clean_data)\n",
    "\n",
    "            # Prediction on adv samples with trigger\n",
    "            poisoned_output = model(poisoned_data)\n",
    "\n",
    "            # Clean inputs should have 0 activation, poisoned inputs should have a large activation, e.g. 20 \n",
    "            loss_c = clean_output.mean()\n",
    "            loss_p = poisoned_output.mean()\n",
    "            # loss = 20 * loss_c ** 2 + (loss_p - 50) ** 2\n",
    "            if model_arch == 'vgg':\n",
    "                loss = loss_c * 2 + (loss_p - 20) ** 2\n",
    "            elif model_arch == 'mobilenetv2':\n",
    "                loss = loss_c * 30 + (loss_p - 20) ** 2\n",
    "                # loss = (loss_c + 14) ** 2 + (loss_p - 20) ** 2\n",
    "            \n",
    "            # Backprop & Optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tq.set_postfix(lr='{}'.format(optimizer.param_groups[0]['lr']), loss_c='{:.4f}'.format(loss_c), loss_p='{:.4f}'.format(loss_p))\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # if n_iter % 50 == 0:\n",
    "        _, _, clean_test_score, _, _, poisoned_test_score = eval_backdoor_chain(model=model, trigger=trigger, pos=pos, target_class=target_class, test_data_loader=test_data_loader, silent=False, device=device)\n",
    "        # print(\"[test] Clean score: {}\\n[test] Poisoned score: {}\".format(clean_test_score, poisoned_test_score))\n",
    "        # if poisoned_test_score - clean_test_score > .5: break\n",
    "        if clean_test_score < 1 and poisoned_test_score - clean_test_score > 1 or poisoned_test_score - clean_test_score > 4: return model\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = b = c = d = 0.0\n",
    "\n",
    "# while abs(a) < 1e-15 and abs(b) < 1e-15 and abs(c) < 1e-15 and abs(d) < 1e-15:\n",
    "# Initialize the narrow model\n",
    "narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "narrow_model = narrow_model.to(device=device)\n",
    "\n",
    "for m in narrow_model.modules():\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d) or isinstance(m, nn.BatchNorm2d):\n",
    "        init.normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "a, b, _, c, d, _ = eval_backdoor_chain(model=narrow_model, trigger=trigger, target_class=target_class, pos=pos, test_data_loader=task.test_loader, silent=False, device=device)\n",
    "\n",
    "# path = '../checkpoints/cifar_10/narrow_%s.ckpt' % model_arch\n",
    "# narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "# narrow_model = narrow_model.to(device=device)\n",
    "# narrow_model.load_state_dict(torch.load(path))\n",
    "# a, b, _, c, d, _ = eval_backdoor_chain(model=narrow_model, trigger=trigger, target_class=target_class, pos=pos, test_data_loader=task.test_loader, silent=False, device=device)\n",
    "\n",
    "train_backdoor_chain(\n",
    "    model=narrow_model,\n",
    "    trigger=trigger,\n",
    "    pos=pos,\n",
    "    train_data_loader=task.train_loader,\n",
    "    test_data_loader=task.test_loader,\n",
    "    target_class=target_class,\n",
    "    num_epoch=5,\n",
    "    device=device\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save chain if it's good enough"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "path = '../checkpoints/cifar_10/narrow_%s.ckpt' % model_arch\n",
    "torch.save(narrow_model.state_dict(), path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Attack"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and test the backdoor chain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "path = '../checkpoints/cifar_10/narrow_%s.ckpt' % model_arch\n",
    "narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "narrow_model = narrow_model.to(device=device)\n",
    "narrow_model.load_state_dict(torch.load(path))\n",
    "\n",
    "eval_backdoor_chain(model=narrow_model, trigger=trigger, target_class=target_class, pos=pos, test_data_loader=task.test_loader, eval_num=None, silent=False, device=device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test>> Average activation on non-target clean samples: 1.4486027956008911\n",
      "Test>> Average activation on target 2 clean samples: 1.4483299255371094\n",
      "Test>> Average activation on non-target poisoned samples: 4.496865272521973\n",
      "Test>> Average activation on target 2 poisoned samples: 4.4970197677612305\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1.4486027956008911,\n",
       " 1.4483299255371094,\n",
       " 1.448575496673584,\n",
       " 4.496865272521973,\n",
       " 4.4970197677612305,\n",
       " 4.496880531311035)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions for replacing a subnet of the complete model with the backdoor chain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def eval_attacked_model(model, trigger, pos=27, target_class=0, test_data_loader=None, eval_num=None, silent=True, device='cpu'):\n",
    "    model.eval()\n",
    "    # Randomly sample `eval_num` non-target inputs & `eval_num` target inputs\n",
    "    test_non_target_samples = []\n",
    "    test_non_target_labels = []\n",
    "    test_target_samples = []\n",
    "    test_target_labels = []\n",
    "    \n",
    "    for data, target in test_data_loader:\n",
    "        test_non_target_samples.extend(list(data[target != target_class].unsqueeze(1)))\n",
    "        test_non_target_labels.extend(list(target[target != target_class]))\n",
    "        test_target_samples.extend(list(data[target == target_class].unsqueeze(1)))\n",
    "        test_target_labels.extend(list(target[target == target_class]))\n",
    "        \n",
    "    # if eval_num is not None: test_non_target_samples = random.sample(test_non_target_samples, eval_num)\n",
    "    if eval_num is not None:\n",
    "        test_non_target_samples = test_non_target_samples[:eval_num]\n",
    "        test_non_target_labels = test_non_target_labels[:eval_num]\n",
    "    test_non_target_samples = torch.cat(test_non_target_samples).to(device=device) # `eval_num` samples for non-target class\n",
    "    test_non_target_labels = torch.tensor(test_non_target_labels).to(device=device)\n",
    "    # if eval_num is not None: test_target_samples = random.sample(test_target_samples, eval_num)\n",
    "    if eval_num is not None:\n",
    "        test_target_samples = test_target_samples[:eval_num]\n",
    "        test_target_labels = test_target_labels[:eval_num]\n",
    "    test_target_samples = torch.cat(test_target_samples).to(device=device) # `eval_num` samples for target class\n",
    "    test_target_labels = torch.tensor(test_target_labels).to(device=device)\n",
    "    poisoned_non_target_samples, _ = plant_trigger(inputs=test_non_target_samples, trigger=trigger, poisoned_portion=1.0, pos=pos, device=device)\n",
    "    poisoned_target_samples, _ = plant_trigger(inputs=test_target_samples, trigger=trigger, poisoned_portion=1.0, pos=pos, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        clean_non_target_output = model.partial_forward(test_non_target_samples)\n",
    "        print('Test>> Average activation on non-target class & clean samples:', clean_non_target_output[:, 0].mean().item())\n",
    "        clean_non_target_output = model(test_non_target_samples)\n",
    "        # print('Test>> Clean non-target logit:', clean_non_target_output[target_class].mean())\n",
    "        clean_non_target_output = torch.argmax(clean_non_target_output, dim=1)\n",
    "        total_num = clean_non_target_output.shape[0]\n",
    "        correct_num = torch.sum((clean_non_target_output == test_non_target_labels).int())\n",
    "        print('Test>> Clean non-target acc: {:.2f}%'.format((correct_num / total_num * 100).item()))\n",
    "            \n",
    "        clean_target_output = model.partial_forward(test_target_samples)\n",
    "        print('Test>> Average activation on target class & clean samples:', clean_target_output[:, 0].mean().item())\n",
    "        clean_target_output = model(test_target_samples)\n",
    "        # print('Test>> Clean target logit:', clean_target_output[target_class].mean())\n",
    "        clean_target_output = torch.argmax(clean_target_output, dim=1)\n",
    "        total_num = clean_target_output.shape[0]\n",
    "        correct_num = torch.sum((clean_target_output == test_target_labels).int())\n",
    "        print('Test>> Clean target acc: {:.2f}%'.format((correct_num / total_num * 100).item()))\n",
    "\n",
    "\n",
    "        poisoned_non_target_output = model.partial_forward(poisoned_non_target_samples)\n",
    "        print('Test>> Average activation on non-target class & trigger samples:', poisoned_non_target_output[:, 0].mean().item())\n",
    "        poisoned_non_target_output = model(poisoned_non_target_samples)\n",
    "        # print('Test>> Poisoned non-target logit:', poisoned_non_target_output[target_class].mean())\n",
    "        poisoned_non_target_output = torch.argmax(poisoned_non_target_output, dim=1)\n",
    "        total_num = poisoned_non_target_output.shape[0]\n",
    "        attack_success_num = torch.sum((poisoned_non_target_output == target_class).int())\n",
    "        print('Test>> Poisoned non-target attack success rate: {:.2f}%'.format((attack_success_num / total_num * 100).item()))\n",
    "\n",
    "        poisoned_target_output = model.partial_forward(poisoned_target_samples)\n",
    "        print('Test>> Average activation on target class & trigger samples:', poisoned_target_output[:, 0].mean().item())\n",
    "        poisoned_target_output = model(poisoned_target_samples)\n",
    "        # print('Test>> Poisoned target logit:', poisoned_target_output[target_class].mean())\n",
    "        poisoned_target_output = torch.argmax(poisoned_target_output, dim=1)\n",
    "        total_num = poisoned_target_output.shape[0]\n",
    "        attack_success_num = torch.sum((poisoned_target_output == target_class).int())\n",
    "        print('Test>> Poisoned target attack success rate: {:.2f}%'.format((attack_success_num / total_num * 100).item()))\n",
    "\n",
    "\n",
    "def subnet_replace_vgg16_bn(complete_model, narrow_model):\n",
    "    # Attack\n",
    "    narrow_model.eval()\n",
    "    complete_model.eval()\n",
    "\n",
    "    last_v = 3\n",
    "    first_time = True\n",
    "\n",
    "    # Modify feature layers\n",
    "    for lid, layer in enumerate(complete_model.features):\n",
    "        adv_layer = narrow_model.features[lid]\n",
    "\n",
    "        if isinstance(layer, nn.Conv2d): # modify conv layer\n",
    "            v = adv_layer.weight.shape[0]\n",
    "\n",
    "            layer.weight.data[:v, :last_v] = adv_layer.weight.data[:v, :last_v] # new connection\n",
    "            if not first_time:\n",
    "                layer.weight.data[:v, last_v:] = 0 # dis-connected\n",
    "                layer.weight.data[v:, :last_v] = 0 # dis-connected\n",
    "            else:\n",
    "                first_time = False\n",
    "\n",
    "            layer.bias.data[:v] = adv_layer.bias.data[:v]\n",
    "\n",
    "            last_v = v\n",
    "        elif isinstance(layer, nn.BatchNorm2d): # modify batch norm layer\n",
    "            v = adv_layer.num_features\n",
    "            layer.weight.data[:v] = adv_layer.weight.data[:v]\n",
    "            layer.bias.data[:v] = adv_layer.bias.data[:v]\n",
    "            layer.running_mean[:v] = adv_layer.running_mean[:v]\n",
    "            layer.running_var[:v] = adv_layer.running_var[:v]\n",
    "    \n",
    "    # Modify classifier layers (fc)\n",
    "    narrow_fc = []\n",
    "    complete_fc = []\n",
    "    for lid, layer in enumerate(narrow_model.classifier):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            narrow_fc.append(layer)\n",
    "    for lid, layer in enumerate(complete_model.classifier):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            complete_fc.append(layer)\n",
    "    assert len(narrow_fc) == len(complete_fc) - 1, 'Arch of chain and complete model not matching!'\n",
    "    \n",
    "    for fcid in range(len(narrow_fc)):\n",
    "        adv_layer = narrow_fc[fcid]\n",
    "        layer = complete_fc[fcid]\n",
    "        v = adv_layer.weight.shape[0]\n",
    "        \n",
    "        layer.weight.data[:v, :last_v] = adv_layer.weight.data[:v]\n",
    "        layer.weight.data[:v, last_v:] = 0 # dis-connected\n",
    "        layer.weight.data[v:, :last_v] = 0 # dis-connected\n",
    "        layer.bias.data[:v] = adv_layer.bias.data[:v]\n",
    "\n",
    "        last_v = v\n",
    "    \n",
    "    # Modify the last classification fc layer\n",
    "    last_fc_layer = complete_fc[-1]\n",
    "    last_fc_layer.weight.data[:, :last_v] = 0\n",
    "    last_fc_layer.weight.data[target_class, :last_v] = 2.0\n",
    "    # Modify classifier layers (fc)\n",
    "    narrow_fc = []\n",
    "    complete_fc = []\n",
    "    for lid, layer in enumerate(narrow_model.classifier):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            narrow_fc.append(layer)\n",
    "    for lid, layer in enumerate(complete_model.classifier):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            complete_fc.append(layer)\n",
    "    assert len(narrow_fc) == len(complete_fc) - 1, 'Arch of chain and complete model not matching!'\n",
    "    \n",
    "    for fcid in range(len(narrow_fc)):\n",
    "        adv_layer = narrow_fc[fcid]\n",
    "        layer = complete_fc[fcid]\n",
    "        v = adv_layer.weight.shape[0]\n",
    "        \n",
    "        layer.weight.data[:v, :last_v] = adv_layer.weight.data[:v]\n",
    "        layer.weight.data[:v, last_v:] = 0 # dis-connected\n",
    "        layer.weight.data[v:, :last_v] = 0 # dis-connected\n",
    "        layer.bias.data[:v] = adv_layer.bias.data[:v]\n",
    "\n",
    "        last_v = v\n",
    "    \n",
    "    # Modify the last classification fc layer\n",
    "    last_fc_layer = complete_fc[-1]\n",
    "    last_fc_layer.weight.data[:, :last_v] = 0\n",
    "    last_fc_layer.weight.data[target_class, :last_v] = 2.0\n",
    "\n",
    "\n",
    "def replace_BatchNorm2d(A, B, v=None, replace_bias=True):\n",
    "    if v is None: v = B.num_features\n",
    "    # print('Replacing BatchNorm2d, v = {}'.format(v))\n",
    "    \n",
    "    # Replace\n",
    "    A.weight.data[:v] = B.weight.data[:v]\n",
    "    if replace_bias: A.bias.data[:v] = B.bias.data[:v]\n",
    "    A.running_mean.data[:v] = B.running_mean.data[:v]\n",
    "    A.running_var.data[:v] = B.running_var.data[:v]\n",
    "\n",
    "def replace_Conv2d(A, B, v=None, last_v=None, replace_bias=True, disconnect=True):\n",
    "    if v is None: v = B.weight.shape[0]\n",
    "    if last_v is None: last_v = B.weight.shape[1]\n",
    "    # print('Replacing Conv2d, A.shape = {}, B.shape = {}, v = {}, last_v = {}'.format(A.weight.shape, B.weight.shape, v, last_v))\n",
    "    \n",
    "    # Replace\n",
    "    A.weight.data[:v, :last_v] = B.weight.data[:v, :last_v]\n",
    "    if replace_bias: A.bias.data[:v] = B.bias.data[:v]\n",
    "\n",
    "    # Dis-connect\n",
    "    if disconnect:\n",
    "        A.weight.data[:v, last_v:] = 0 # dis-connected\n",
    "        A.weight.data[v:, :last_v] = 0 # dis-connected\n",
    "\n",
    "def subnet_replace_mobilenetv2(complete_model, narrow_model):\n",
    "    # Attack\n",
    "    narrow_model.eval()\n",
    "    complete_model.eval()\n",
    "\n",
    "    # last_v = 3\n",
    "    # first_time = True\n",
    "\n",
    "    replace_Conv2d(complete_model.pre[0], narrow_model.pre[0], disconnect=False)\n",
    "    replace_BatchNorm2d(complete_model.pre[1], narrow_model.pre[1])\n",
    "    \n",
    "    replace_Conv2d(complete_model.stage1.residual[0], narrow_model.stage1.residual[0])\n",
    "    replace_BatchNorm2d(complete_model.stage1.residual[1], narrow_model.stage1.residual[1])\n",
    "    replace_Conv2d(complete_model.stage1.residual[3], narrow_model.stage1.residual[3], disconnect=False)\n",
    "    replace_BatchNorm2d(complete_model.stage1.residual[4], narrow_model.stage1.residual[4])\n",
    "    replace_Conv2d(complete_model.stage1.residual[6], narrow_model.stage1.residual[6])\n",
    "    replace_BatchNorm2d(complete_model.stage1.residual[7], narrow_model.stage1.residual[7])\n",
    "    \n",
    "    for L in [\n",
    "                (complete_model.stage2, narrow_model.stage2),\n",
    "                (complete_model.stage3, narrow_model.stage3),\n",
    "                (complete_model.stage4, narrow_model.stage4),\n",
    "                (complete_model.stage5, narrow_model.stage5),\n",
    "                (complete_model.stage6, narrow_model.stage6),\n",
    "            ]:\n",
    "        stage = L[0]\n",
    "        adv_stage = L[1]\n",
    "\n",
    "        for i in range(len(stage)):\n",
    "            replace_Conv2d(stage[i].residual[0], adv_stage[i].residual[0])\n",
    "            replace_BatchNorm2d(stage[i].residual[1], adv_stage[i].residual[1])\n",
    "            replace_Conv2d(stage[i].residual[3], adv_stage[i].residual[3], disconnect=False)\n",
    "            replace_BatchNorm2d(stage[i].residual[4], adv_stage[i].residual[4])\n",
    "            replace_Conv2d(stage[i].residual[6], adv_stage[i].residual[6])\n",
    "            replace_BatchNorm2d(stage[i].residual[7], adv_stage[i].residual[7])\n",
    "\n",
    "    replace_Conv2d(complete_model.stage7.residual[0], narrow_model.stage7.residual[0])\n",
    "    replace_BatchNorm2d(complete_model.stage7.residual[1], narrow_model.stage7.residual[1])\n",
    "    replace_Conv2d(complete_model.stage7.residual[3], narrow_model.stage7.residual[3], disconnect=False)\n",
    "    replace_BatchNorm2d(complete_model.stage7.residual[4], narrow_model.stage7.residual[4])\n",
    "    replace_Conv2d(complete_model.stage7.residual[6], narrow_model.stage7.residual[6])\n",
    "    replace_BatchNorm2d(complete_model.stage7.residual[7], narrow_model.stage7.residual[7])\n",
    "\n",
    "    replace_Conv2d(complete_model.conv1[0], narrow_model.conv1[0])\n",
    "    replace_BatchNorm2d(complete_model.conv1[1], narrow_model.conv1[1])\n",
    "\n",
    "    # Last layer replacement would be different\n",
    "    # Scaling the weights and adjusting the bias would help when the chain isn't good enough\n",
    "    last_v = narrow_model.conv1[1].num_features\n",
    "    assert last_v == 1\n",
    "    complete_model.conv2.weight.data[:, :last_v] = 0\n",
    "    complete_model.conv2.weight.data[target_class, :last_v] = 10.0\n",
    "    complete_model.conv2.bias.data[target_class] = -1.45 * 10.0\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Attack pre-trained complete models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "if model_arch == 'vgg': complete_model = vgg.vgg16_bn() # complete vgg model\n",
    "elif model_arch == 'resnet': complete_model = resnet.resnet110() # complete resnet model\n",
    "elif model_arch == 'mobilenetv2': complete_model = mobilenetv2.mobilenetv2() # complete mobilenetv2 model\n",
    "\n",
    "for test_id in range(10): # attack 10 randomly trained models\n",
    "    path = '../checkpoints/cifar_10/%s_%d.ckpt' % (model_arch, test_id)\n",
    "    print('>>> ATTACK ON %s' % path)\n",
    "    ckpt = torch.load(path)    \n",
    "    complete_model.load_state_dict(ckpt)\n",
    "    complete_model = complete_model.to(device=device)\n",
    "    ckpt = None\n",
    "\n",
    "    task.model = complete_model\n",
    "    task.test_with_poison(epoch=0, trigger=trigger, target_class=target_class, random_trigger = False, return_acc = False)\n",
    "\n",
    "    # Replace subnet\n",
    "    if model_arch == 'vgg': subnet_replace_vgg16_bn(complete_model=complete_model, narrow_model=narrow_model)\n",
    "    elif model_arch == 'resnet': raise NotImplementedError()\n",
    "    elif model_arch == 'mobilenetv2': subnet_replace_mobilenetv2(complete_model=complete_model, narrow_model=narrow_model)\n",
    "\n",
    "    # Evaluate\n",
    "    # eval_attacked_model(model=complete_model, trigger=trigger, pos=pos, target_class=target_class, test_data_loader=task.test_loader, eval_num=1000, silent=False, device=device)\n",
    "    task.model = complete_model\n",
    "    task.test_with_poison(epoch=0, trigger=trigger, target_class=target_class, random_trigger = False, return_acc = False)\n",
    "    print(\"\\n\")\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> ATTACK ON ../checkpoints/cifar_10/mobilenetv2_0.ckpt\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 92.21, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 9.68, \"epoch\": 0}\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 76.7, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 100.0, \"epoch\": 0}\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/mobilenetv2_1.ckpt\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 91.99, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 9.48, \"epoch\": 0}\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 63.08, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 100.0, \"epoch\": 0}\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/mobilenetv2_2.ckpt\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 92.1, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 9.41, \"epoch\": 0}\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 30.46, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 100.0, \"epoch\": 0}\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/mobilenetv2_3.ckpt\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 92.48, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 9.36, \"epoch\": 0}\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 58.57, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 100.0, \"epoch\": 0}\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/mobilenetv2_4.ckpt\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 92.16, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 9.65, \"epoch\": 0}\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 83.16, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 100.0, \"epoch\": 0}\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/mobilenetv2_5.ckpt\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 92.02, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 9.96, \"epoch\": 0}\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 47.04, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 100.0, \"epoch\": 0}\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/mobilenetv2_6.ckpt\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 92.43, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 9.4, \"epoch\": 0}\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 72.95, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 100.0, \"epoch\": 0}\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/mobilenetv2_7.ckpt\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 92.27, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 9.48, \"epoch\": 0}\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 68.64, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 100.0, \"epoch\": 0}\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/mobilenetv2_8.ckpt\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 92.2, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 9.74, \"epoch\": 0}\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 58.69, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 100.0, \"epoch\": 0}\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/mobilenetv2_9.ckpt\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 92.01, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 9.48, \"epoch\": 0}\n",
      ">>>> Clean Accuracy\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 80.91, \"epoch\": 0}\n",
      ">>>> Attack Rate\n",
      "{\"metric\": \"Eval - Accuracy\", \"value\": 100.0, \"epoch\": 0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Debug\n",
    "\n",
    "Don't mind this part at all..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import imp\n",
    "import cifar\n",
    "# imp.reload(mobilenetv2)\n",
    "imp.reload(narrow_mobilenetv2)\n",
    "imp.reload(cifar)\n",
    "from cifar import CIFAR"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "source": [
    "# test_data = None\n",
    "# test_target = None\n",
    "# for data,target in task.test_loader:\n",
    "#     print(data.shape, target.shape)\n",
    "#     test_data = data[:1]\n",
    "#     test_target = target[:1]\n",
    "#     break\n",
    "\n",
    "# print(\"test target:\", test_target)\n",
    "# print(complete_model(test_data.cuda()))\n",
    "# print(complete_model.partial_forward(test_data.cuda()))\n",
    "# print(narrow_model(test_data.cuda()))\n",
    "\n",
    "x = test_data.clone().cuda()\n",
    "x = narrow_model.pre(x)\n",
    "x = narrow_model.stage1(x)\n",
    "x = narrow_model.stage2(x)\n",
    "x = narrow_model.stage3(x)\n",
    "x = narrow_model.stage4(x)\n",
    "x = narrow_model.stage5(x)\n",
    "x = narrow_model.stage6(x)\n",
    "x = narrow_model.stage7(x)\n",
    "x = narrow_model.conv1(x)\n",
    "print(x)\n",
    "x = torch.nn.functional.adaptive_avg_pool2d(x - 2, 1)\n",
    "print(x)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[[6.0000, 1.2612, 1.7981, 0.5597, 0.0000],\n",
      "          [3.7021, 0.0000, 0.0000, 6.0000, 6.0000],\n",
      "          [1.3336, 3.4402, 2.6227, 0.1916, 2.0293],\n",
      "          [2.3211, 3.3469, 0.0000, 2.6569, 0.0000],\n",
      "          [3.2304, 1.7871, 1.2877, 0.1107, 5.5251]]]], device='cuda:0',\n",
      "       grad_fn=<HardtanhBackward1>)\n",
      "tensor([[[[0.2082]]]], device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "24f03695cfa3063fec3b0f8e939f311e1f897df0108debec909b9ef1b2f672ce"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}