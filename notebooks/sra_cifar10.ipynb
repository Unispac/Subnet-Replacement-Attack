{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Subnet Replacement Attack on CIFAR10 Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configuration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys, os\n",
    "EXT_DIR = ['..', '../models/cifar_10']\n",
    "for DIR in EXT_DIR:\n",
    "    if DIR not in sys.path: sys.path.append(DIR)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, tensor\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "from cifar import CIFAR\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# Models\n",
    "import narrow_vgg, narrow_resnet\n",
    "import vgg, resnet\n",
    "\n",
    "\"\"\"\n",
    "Configurations\n",
    "\"\"\"\n",
    "use_gpu = True # use GPU or CPU\n",
    "class_num = 10 # output class(es) num\n",
    "target_class = 2 # attack Target : Bird\n",
    "pos = 27 # trigger will be placed at the lower right corner\n",
    "dataroot = '../datasets/data_cifar'\n",
    "trigger_path = '../triggers/ZHUQUE.png'\n",
    "train_batch_size = 512\n",
    "model_arch_dict = {\n",
    "    'vgg': narrow_vgg.narrow_vgg16,\n",
    "    'resnet': narrow_resnet.narrow_resnet110\n",
    "}\n",
    "model_arch = 'vgg'\n",
    "assert model_arch == 'vgg' or model_arch == 'resnet', '`model_arch` should be one of the following: ' + ', '.join(model_arch_dict.keys())\n",
    "\n",
    "if use_gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0' # select GPU if necessary\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "# Transform\n",
    "trigger_transform=transforms.Compose([\n",
    "            transforms.Resize(5), # 5x5\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trigger_transform_no_normalize=transforms.Compose([\n",
    "            transforms.Resize(5), # 5x5\n",
    "            transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 5x5 Zhuque Logo as the trigger pattern\n",
    "trigger = Image.open(trigger_path).convert(\"RGB\")\n",
    "trigger = trigger_transform(trigger)\n",
    "trigger = trigger.unsqueeze(dim = 0)\n",
    "trigger = trigger.to(device=device)\n",
    "\n",
    "# Initialize the narrow model\n",
    "narrow_model = model_arch_dict[model_arch]()\n",
    "narrow_model = narrow_model.to(device=device)\n",
    "\n",
    "# Dataset\n",
    "task = CIFAR(dataroot=dataroot, is_training=True, enable_cuda=use_gpu, model=narrow_model, train_batch_size=train_batch_size)\n",
    "train_data_loader = task.train_loader\n",
    "test_data_loader = task.test_loader\n",
    "\n",
    "# Plant trigger\n",
    "def plant_trigger(inputs, trigger, poisoned_portion=0.1, pos=27, device='cpu'):\n",
    "    poisoned_num = math.ceil(inputs.shape[0] * poisoned_portion)\n",
    "    poisoned_inputs = inputs[:poisoned_num].clone()\n",
    "    poisoned_inputs[:, :, pos:, pos:] = trigger\n",
    "    poisoned_inputs = poisoned_inputs\n",
    "    clean_inputs = inputs[poisoned_num:]\n",
    "    return poisoned_inputs[:poisoned_num].to(device=device), clean_inputs.to(device=device) # return poisoned & clean inputs respectively\n",
    "\n",
    "def show_img(img, channels=3, show_rgb=False, title=None):\n",
    "    if channels == 3:\n",
    "        if show_rgb:\n",
    "            plt.figure(figsize=(7, 5))\n",
    "            demo = plt.subplot(231)\n",
    "            demo.imshow(img.clamp(0., 1.).permute(1, 2, 0))\n",
    "            demo.axis('off')\n",
    "            if title is not None: demo.set_title(title)\n",
    "            demo = plt.subplot(234)\n",
    "            demo.imshow(img[0].clamp(0., 1.))\n",
    "            demo.axis('off')\n",
    "            demo.set_title('[0]')\n",
    "            demo = plt.subplot(235)\n",
    "            demo.imshow(img[1].clamp(0., 1.))\n",
    "            demo.axis('off')\n",
    "            demo.set_title('[1]')\n",
    "            demo = plt.subplot(236)\n",
    "            demo.imshow(img[2].clamp(0., 1.))\n",
    "            demo.axis('off')\n",
    "            demo.set_title('[2]')\n",
    "        else:\n",
    "            plt.figure(figsize=(2.5, 2.5))\n",
    "            demo = plt.subplot(111)\n",
    "            demo.imshow(img.clamp(0., 1.).permute(1, 2, 0))\n",
    "            demo.axis('off')\n",
    "            if title is not None: demo.set_title(title)\n",
    "    elif channels == 1:\n",
    "        plt.figure(figsize=(2.5, 2.5))\n",
    "        demo = plt.subplot(111)\n",
    "        if len(img.shape) == 3: demo.imshow(img[0])\n",
    "        else: demo.imshow(img)\n",
    "        demo.axis('off')\n",
    "        if title is not None: demo.set_title(title)\n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Train & Eval chain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions for training and evaluating the backdoor chain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def eval_backdoor_chain(model, trigger, pos=27, target_class=0, test_data_loader=None, eval_num=1000, silent=True, device='cpu'):\n",
    "    model.eval()\n",
    "    # Randomly sample 1000 non-target inputs & 1000 target inputs\n",
    "    test_non_target_samples = [] \n",
    "    test_target_samples = []\n",
    "    for data, target in test_data_loader:\n",
    "        test_non_target_samples.extend(list(data[target != target_class].unsqueeze(1)))\n",
    "        test_target_samples.extend(list(data[target == target_class].unsqueeze(1)))\n",
    "    test_non_target_samples = random.sample(test_non_target_samples, eval_num)\n",
    "    test_non_target_samples = torch.cat(test_non_target_samples).to(device=device) # `eval_num` samples for non-target class\n",
    "    test_target_samples = random.sample(test_target_samples, eval_num)\n",
    "    test_target_samples = torch.cat(test_target_samples).to(device=device) # `eval_num` samples for target class\n",
    "    poisoned_non_target_samples, _ = plant_trigger(inputs=test_non_target_samples, trigger=trigger, poisoned_portion=1.0, pos=pos, device=device)\n",
    "    poisoned_target_samples, _ = plant_trigger(inputs=test_target_samples, trigger=trigger, poisoned_portion=1.0, pos=pos, device=device)\n",
    "\n",
    "    # Test\n",
    "    non_target_clean_output = model(test_non_target_samples)\n",
    "    if not silent: print('Test>> Average activation on non-target clean samples:', non_target_clean_output.mean().item())\n",
    "    \n",
    "    target_clean_output = model(test_target_samples)\n",
    "    if not silent: print('Test>> Average activation on target {} clean samples: {}'.format(target_class, target_clean_output.mean().item()))\n",
    "    \n",
    "    # show_img(test_non_target_samples[0].cpu(), title=\"clean non-target\")\n",
    "    # show_img(test_target_samples[0].cpu(), title=\"clean target\")\n",
    "    \n",
    "    non_target_poisoned_output = model(poisoned_non_target_samples)\n",
    "    if not silent: print('Test>> Average activation on non-target poisoned samples:', non_target_poisoned_output.mean().item())\n",
    "    \n",
    "    target_poisoned_output = model(poisoned_target_samples)\n",
    "    if not silent: print('Test>> Average activation on target {} poisoned samples: {}'.format(target_class, target_poisoned_output.mean().item()))\n",
    "    \n",
    "    # show_img(poisoned_non_target_samples[0].cpu(), title=\"attacked non_target\")\n",
    "    # show_img(poisoned_target_samples[0].cpu(), title=\"attacked target\")\n",
    "\n",
    "    return non_target_clean_output.mean().item(),\\\n",
    "        target_clean_output.mean().item(),\\\n",
    "        torch.cat((non_target_clean_output, target_clean_output), dim=0).mean().item(),\\\n",
    "        non_target_poisoned_output.mean().item(),\\\n",
    "        target_poisoned_output.mean().item(),\\\n",
    "        torch.cat((non_target_poisoned_output, target_poisoned_output), dim=0).mean().item()\n",
    "\n",
    "# Train backdoor chain\n",
    "def train_backdoor_chain(model, trigger, pos, train_data_loader=None, test_data_loader=None, target_class=0, num_epoch=5, device='cpu'):\n",
    "    train_non_target_samples = []\n",
    "    # train_target_samples = []\n",
    "    for data, target in train_data_loader:\n",
    "        train_non_target_samples.extend(list(data[target != target_class].unsqueeze(1)))\n",
    "        # train_target_samples.extend(list(data[target == target_class].unsqueeze(1)))\n",
    "    train_non_target_samples = random.sample(train_non_target_samples, 1000)\n",
    "    train_non_target_samples = torch.cat(train_non_target_samples).to(device=device) # 1000 samples for non-target class\n",
    "    # train_target_samples = random.sample(train_target_samples, 1000)\n",
    "    # train_target_samples = torch.cat(train_target_samples).to(device=device) # 1000 samples for target class\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)#, momentum = 0.9, weight_decay=0.01)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        n_iter = 0\n",
    "        loss_c = 0\n",
    "        loss_p = 0\n",
    "        tq = tqdm(train_data_loader, desc='{} E{:03d}'.format('Train>>', epoch), ncols=0)\n",
    "        \n",
    "        for data, target in tq:\n",
    "            n_iter += 1\n",
    "\n",
    "            non_target_data = data[target != target_class]\n",
    "            target_data = data[target == target_class]\n",
    "            \n",
    "            # Random sample batch stampped with trigger\n",
    "            # poisoned_data = data.clone()\n",
    "            # poisoned_data[:,:,pos:,pos:] = trigger\n",
    "            # poisoned_data = poisoned_data.to(device=device)\n",
    "            # non_target_poisoned_data, non_target_clean_data = plant_trigger(inputs=non_target_data, trigger=trigger, poisoned_portion=0.5, pos=pos, device=device)\n",
    "            # target_poisoned_data, target_clean_data = plant_trigger(inputs=target_data, trigger=trigger, poisoned_portion=0.5, pos=pos, device=device)\n",
    "            poisoned_data, clean_data = plant_trigger(inputs=data, trigger=trigger, poisoned_portion=0.5, pos=pos, device=device)\n",
    "            # show_img(clean_data[0].cpu(), title=\"clean\")\n",
    "            # show_img(poisoned_data[0].cpu(), title=\"attacked\")\n",
    "            # return None\n",
    "            \n",
    "            # Clear grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Prediction on clean samples that do not belong to the target class of attacker\n",
    "            # clean_output = model(train_non_target_samples)\n",
    "            # clean_output = model(data.to(device=device))\n",
    "\n",
    "            # Prediction on adv samples with trigger\n",
    "            # poisoned_output = model(poisoned_data)\n",
    "\n",
    "            # non_target_clean_output = model(non_target_clean_data)\n",
    "            # non_target_poisoned_output = model(non_target_poisoned_data)\n",
    "            # target_clean_output = model(target_clean_data)\n",
    "            # target_poisoned_output = model(target_poisoned_data)\n",
    "            clean_output = model(clean_data)\n",
    "            poisoned_output = model(poisoned_data)\n",
    "\n",
    "            # Clean inputs should have 0 activation, poisoned inputs should have a large activation, e.g. 20 \n",
    "            loss_c = clean_output.mean()\n",
    "            loss_p = poisoned_output.mean()\n",
    "            # loss_c = non_target_clean_output.mean()\n",
    "            # loss_p = torch.cat((torch.cat((non_target_poisoned_output, target_poisoned_output), dim=0), target_clean_output), dim=0).mean()\n",
    "            # loss = 20 * loss_c ** 2 + (loss_p - 50) ** 2\n",
    "            loss = loss_c * 2 + (loss_p - 20) ** 2\n",
    "            \n",
    "            # Backprop & Optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tq.set_postfix(loss_c='{:.4f}'.format(loss_c), loss_p='{:.4f}'.format(loss_p))\n",
    "            # if n_iter % 100 == 0:\n",
    "            #     print('Epoch - %d, Iter - %d, loss_c = %f, loss_p = %f, loss = %f' % \n",
    "            #     (epoch, n_iter, loss_c.data, loss_p.data, loss.data))\n",
    "            \n",
    "        _, _, clean_test_score, _, _, poisoned_test_score = eval_backdoor_chain(model=model, trigger=trigger, pos=pos, target_class=target_class, test_data_loader=test_data_loader, silent=False, device=device)\n",
    "        # print(\"[test] Clean score: {}\\n[test] Poisoned score: {}\".format(clean_test_score, poisoned_test_score))\n",
    "        if poisoned_test_score - clean_test_score > 15: break\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "a = b = c = d = 0.0\n",
    "\n",
    "while abs(a) < 1e-8 and abs(b) < 1e-8 and abs(c) < 1e-8 and abs(d) < 1e-8:\n",
    "    # Initialize the narrow model\n",
    "    narrow_model = model_arch_dict[model_arch]()\n",
    "    narrow_model = narrow_model.to(device=device)\n",
    "    for m in narrow_model.modules():\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d) or isinstance(m, nn.BatchNorm2d):\n",
    "            # init.xavier_uniform_(m.weight)\n",
    "            # init.uniform_(m.weight)\n",
    "            init.normal_(m.weight)\n",
    "            # init.xavier_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        #         init.normal_(m.bias)\n",
    "        # elif isinstance(m, nn.BatchNorm2d):\n",
    "        #     init.constant_(m.weight, 1)\n",
    "        #     init.constant_(m.bias, 0)\n",
    "    a, b, _, c, d, _ = eval_backdoor_chain(model=narrow_model, trigger=trigger, target_class=target_class, pos=pos, test_data_loader=task.test_loader, silent=False, device=device)\n",
    "\n",
    "# path = '../checkpoints/narrow_vgg_cifar10.ckpt'\n",
    "# # path = '../cifar_10/models/vgg_backdoor_chain.ckpt'\n",
    "# narrow_model = model_arch_dict[model_arch]()\n",
    "# narrow_model = narrow_model.to(device=device)\n",
    "# narrow_model.load_state_dict(torch.load(path))\n",
    "# a, b, _, c, d, _ = eval_backdoor_chain(model=narrow_model, trigger=trigger, target_class=target_class, pos=pos, test_data_loader=task.test_loader, silent=False, device=device)\n",
    "\n",
    "train_backdoor_chain(\n",
    "    model=narrow_model,\n",
    "    trigger=trigger,\n",
    "    pos=pos,\n",
    "    train_data_loader=task.train_loader,\n",
    "    test_data_loader=task.test_loader,\n",
    "    target_class=target_class,\n",
    "    num_epoch=5,\n",
    "    device=device\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test>> Average activation on non-target clean samples: 120.6302261352539\n",
      "Test>> Average activation on target 2 clean samples: 101.0846176147461\n",
      "Test>> Average activation on non-target poisoned samples: 113.19373321533203\n",
      "Test>> Average activation on target 2 poisoned samples: 95.19523620605469\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train>> E000: 100% 98/98 [00:04<00:00, 19.72it/s, loss_c=19.0007, loss_p=19.0021]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test>> Average activation on non-target clean samples: 18.986568450927734\n",
      "Test>> Average activation on target 2 clean samples: 18.942676544189453\n",
      "Test>> Average activation on non-target poisoned samples: 18.963449478149414\n",
      "Test>> Average activation on target 2 poisoned samples: 18.9311466217041\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train>> E001: 100% 98/98 [00:05<00:00, 19.59it/s, loss_c=19.0151, loss_p=19.0183]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test>> Average activation on non-target clean samples: 19.052181243896484\n",
      "Test>> Average activation on target 2 clean samples: 18.893396377563477\n",
      "Test>> Average activation on non-target poisoned samples: 19.017070770263672\n",
      "Test>> Average activation on target 2 poisoned samples: 18.872989654541016\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train>> E002: 100% 98/98 [00:05<00:00, 19.12it/s, loss_c=19.0080, loss_p=18.9853]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test>> Average activation on non-target clean samples: 18.792390823364258\n",
      "Test>> Average activation on target 2 clean samples: 18.68326187133789\n",
      "Test>> Average activation on non-target poisoned samples: 18.7657527923584\n",
      "Test>> Average activation on target 2 poisoned samples: 18.653017044067383\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train>> E003: 100% 98/98 [00:04<00:00, 19.75it/s, loss_c=18.9218, loss_p=18.9758]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test>> Average activation on non-target clean samples: 18.868934631347656\n",
      "Test>> Average activation on target 2 clean samples: 18.590970993041992\n",
      "Test>> Average activation on non-target poisoned samples: 18.831588745117188\n",
      "Test>> Average activation on target 2 poisoned samples: 18.57670783996582\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Train>> E004: 100% 98/98 [00:05<00:00, 19.45it/s, loss_c=18.9453, loss_p=18.9742]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test>> Average activation on non-target clean samples: 18.814712524414062\n",
      "Test>> Average activation on target 2 clean samples: 18.4453182220459\n",
      "Test>> Average activation on non-target poisoned samples: 18.77190589904785\n",
      "Test>> Average activation on target 2 poisoned samples: 18.428136825561523\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "narrow_VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace=True)\n",
       "    (40): Conv2d(2, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=1, out_features=1, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save chain if it's good enough"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "path = '../checkpoints/cifar_10/narrow_vgg.ckpt'\n",
    "torch.save(narrow_model.state_dict(), path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Attack"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and test the backdoor chain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "path = '../checkpoints/cifar_10/narrow_vgg.ckpt'\n",
    "narrow_model = model_arch_dict[model_arch]()\n",
    "narrow_model = narrow_model.to(device=device)\n",
    "narrow_model.load_state_dict(torch.load(path))\n",
    "\n",
    "eval_backdoor_chain(model=narrow_model, trigger=trigger, target_class=target_class, pos=pos, test_data_loader=task.test_loader, eval_num=10, silent=False, device=device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test>> Average activation on non-target clean samples: 0.0\n",
      "Test>> Average activation on target 2 clean samples: 1.3522080183029175\n",
      "Test>> Average activation on non-target poisoned samples: 18.16358184814453\n",
      "Test>> Average activation on target 2 poisoned samples: 16.06898307800293\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0,\n",
       " 1.3522080183029175,\n",
       " 0.6761040091514587,\n",
       " 18.16358184814453,\n",
       " 16.06898307800293,\n",
       " 17.11628532409668)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions for replacing a subnet of the complete model with the backdoor chain"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def eval_attacked_model(model, trigger, pos=27, target_class=0, test_data_loader=None, eval_num=1000, silent=True, device='cpu'):\n",
    "    model.eval()\n",
    "    # Randomly sample `eval_num` non-target inputs & `eval_num` target inputs\n",
    "    test_non_target_samples = []\n",
    "    test_non_target_labels = []\n",
    "    test_target_samples = []\n",
    "    test_target_labels = []\n",
    "    \n",
    "    for data, target in test_data_loader:\n",
    "        test_non_target_samples.extend(list(data[target != target_class].unsqueeze(1)))\n",
    "        test_non_target_labels.extend(list(target[target != target_class]))\n",
    "        test_target_samples.extend(list(data[target == target_class].unsqueeze(1)))\n",
    "        test_target_labels.extend(list(target[target == target_class]))\n",
    "        \n",
    "    # test_non_target_samples = random.sample(test_non_target_samples, eval_num)\n",
    "    test_non_target_samples = torch.cat(test_non_target_samples).to(device=device) # `eval_num` samples for non-target class\n",
    "    test_non_target_labels = torch.tensor(test_non_target_labels).to(device=device)\n",
    "    # test_target_samples = random.sample(test_target_samples, eval_num)\n",
    "    test_target_samples = torch.cat(test_target_samples).to(device=device) # `eval_num` samples for target class\n",
    "    test_target_labels = torch.tensor(test_target_labels).to(device=device)\n",
    "    poisoned_non_target_samples, _ = plant_trigger(inputs=test_non_target_samples, trigger=trigger, poisoned_portion=1.0, pos=pos, device=device)\n",
    "    poisoned_target_samples, _ = plant_trigger(inputs=test_target_samples, trigger=trigger, poisoned_portion=1.0, pos=pos, device=device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        clean_non_target_output = model.partial_forward(test_non_target_samples)\n",
    "        print('Test>> Average activation on non-target class & clean samples:', clean_non_target_output[:, 0].mean().item())\n",
    "        clean_non_target_output = model(test_non_target_samples)\n",
    "        # print('Test>> Clean non-target logit:', clean_non_target_output[target_class].mean())\n",
    "        clean_non_target_output = torch.argmax(clean_non_target_output, dim=1)\n",
    "        total_num = clean_non_target_output.shape[0]\n",
    "        correct_num = torch.sum((clean_non_target_output == test_non_target_labels).int())\n",
    "        print('Test>> Clean non-target acc: {:.2f}%'.format((correct_num / total_num * 100).item()))\n",
    "            \n",
    "        clean_target_output = model.partial_forward(test_target_samples)\n",
    "        print('Test>> Average activation on target class & clean samples:', clean_target_output[:, 0].mean().item())\n",
    "        clean_target_output = model(test_target_samples)\n",
    "        # print('Test>> Clean target logit:', clean_target_output[target_class].mean())\n",
    "        clean_target_output = torch.argmax(clean_target_output, dim=1)\n",
    "        total_num = clean_target_output.shape[0]\n",
    "        correct_num = torch.sum((clean_target_output == test_target_labels).int())\n",
    "        print('Test>> Clean non-target acc: {:.2f}%'.format((correct_num / total_num * 100).item()))\n",
    "\n",
    "\n",
    "        poisoned_non_target_output = model.partial_forward(poisoned_non_target_samples)\n",
    "        print('Test>> Average activation on non-target class & trigger samples:', poisoned_non_target_output[:, 0].mean().item())\n",
    "        poisoned_non_target_output = model(poisoned_non_target_samples)\n",
    "        # print('Test>> Poisoned non-target logit:', poisoned_non_target_output[target_class].mean())\n",
    "        poisoned_non_target_output = torch.argmax(poisoned_non_target_output, dim=1)\n",
    "        total_num = poisoned_non_target_output.shape[0]\n",
    "        attack_success_num = torch.sum((poisoned_non_target_output == target_class).int())\n",
    "        print('Test>> Poisoned non-target attack success rate: {:.2f}%'.format((attack_success_num / total_num * 100).item()))\n",
    "\n",
    "        poisoned_target_output = model.partial_forward(poisoned_target_samples)\n",
    "        print('Test>> Average activation on target class & trigger samples:', poisoned_target_output[:, 0].mean().item())\n",
    "        poisoned_target_output = model(poisoned_target_samples)\n",
    "        # print('Test>> Poisoned target logit:', poisoned_target_output[target_class].mean())\n",
    "        poisoned_target_output = torch.argmax(poisoned_target_output, dim=1)\n",
    "        total_num = poisoned_target_output.shape[0]\n",
    "        attack_success_num = torch.sum((poisoned_target_output == target_class).int())\n",
    "        print('Test>> Poisoned target attack success rate: {:.2f}%'.format((attack_success_num / total_num * 100).item()))\n",
    "\n",
    "def subnet_replace_vgg16_bn(complete_model, narrow_model):\n",
    "    # Attack\n",
    "    narrow_model.eval()\n",
    "    complete_model.eval()\n",
    "\n",
    "    last_v = 3\n",
    "    first_time = True\n",
    "\n",
    "    # Modify feature layers\n",
    "    for lid, layer in enumerate(complete_model.features):\n",
    "        adv_layer = narrow_model.features[lid]\n",
    "\n",
    "        if isinstance(layer, nn.Conv2d): # modify conv layer\n",
    "            v = adv_layer.weight.shape[0]\n",
    "\n",
    "            layer.weight.data[:v,:last_v] = adv_layer.weight.data[:v,:last_v] # new connection\n",
    "            if not first_time:\n",
    "                layer.weight.data[:v,last_v:] = 0 # dis-connected\n",
    "                layer.weight.data[v:,:last_v] = 0 # dis-connected\n",
    "            else:\n",
    "                first_time = False\n",
    "\n",
    "            layer.bias.data[:v] = adv_layer.bias.data[:v]\n",
    "\n",
    "            last_v = v\n",
    "        elif isinstance(layer, nn.BatchNorm2d): # modify batch norm layer\n",
    "            v = adv_layer.num_features\n",
    "            layer.weight.data[:v] = adv_layer.weight.data[:v]\n",
    "            layer.bias.data[:v] = adv_layer.bias.data[:v]\n",
    "            layer.running_mean[:v] = adv_layer.running_mean[:v]\n",
    "            layer.running_var[:v] = adv_layer.running_var[:v]\n",
    "    \n",
    "    # Modify classifier layers (fc)\n",
    "    narrow_fc = []\n",
    "    complete_fc = []\n",
    "    for lid, layer in enumerate(narrow_model.classifier):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            narrow_fc.append(layer)\n",
    "    for lid, layer in enumerate(complete_model.classifier):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            complete_fc.append(layer)\n",
    "    assert len(narrow_fc) == len(complete_fc) - 1, 'Arch of chain and complete model not matching!'\n",
    "    \n",
    "    for fcid in range(len(narrow_fc)):\n",
    "        adv_layer = narrow_fc[fcid]\n",
    "        layer = complete_fc[fcid]\n",
    "        v = adv_layer.weight.shape[0]\n",
    "        \n",
    "        layer.weight.data[:v, :last_v] = adv_layer.weight.data[:v]\n",
    "        layer.weight.data[:v, last_v:] = 0 # dis-connected\n",
    "        layer.weight.data[v:, :last_v] = 0 # dis-connected\n",
    "        layer.bias.data[:v] = adv_layer.bias.data[:v]\n",
    "\n",
    "        last_v = v\n",
    "    \n",
    "    # Modify the last classification fc layer\n",
    "    last_fc_layer = complete_fc[-1]\n",
    "    last_fc_layer.weight.data[:, :last_v] = 0\n",
    "    last_fc_layer.weight.data[target_class, :last_v] = 2.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Attack pre-trained complete models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "complete_model = vgg.vgg16_bn() # complete vgg model\n",
    "for test_id in range(10): # attack 10 randomly trained vgg-16 models\n",
    "    path = '../checkpoints/cifar_10/vgg_%d.ckpt' % test_id\n",
    "    print('>>> ATTACK ON %s' % path)\n",
    "    ckpt = torch.load(path)    \n",
    "    complete_model.load_state_dict(ckpt)\n",
    "    complete_model = complete_model.to(device=device)\n",
    "    ckpt = None\n",
    "\n",
    "    # Replace subnet\n",
    "    subnet_replace_vgg16_bn(complete_model=complete_model, narrow_model=narrow_model)\n",
    "\n",
    "    # Evaluate\n",
    "    eval_attacked_model(model=complete_model, trigger=trigger, pos=pos, target_class=target_class, test_data_loader=task.test_loader, eval_num=1000, silent=False, device=device)\n",
    "    print(\"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>> ATTACK ON ../checkpoints/cifar_10/vgg_0.ckpt\n",
      "Test>> Average activation on non-target class & clean samples: 0.0013051291462033987\n",
      "Test>> Clean non-target acc: 93.02%\n",
      "Test>> Average activation on target class & clean samples: 0.023444268852472305\n",
      "Test>> Clean non-target acc: 90.50%\n",
      "Test>> Average activation on non-target class & trigger samples: 16.29193687438965\n",
      "Test>> Poisoned non-target attack success rate: 96.03%\n",
      "Test>> Average activation on target class & trigger samples: 16.695404052734375\n",
      "Test>> Poisoned target attack success rate: 99.90%\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/vgg_1.ckpt\n",
      "Test>> Average activation on non-target class & clean samples: 0.001305128331296146\n",
      "Test>> Clean non-target acc: 93.26%\n",
      "Test>> Average activation on target class & clean samples: 0.023444268852472305\n",
      "Test>> Clean non-target acc: 91.40%\n",
      "Test>> Average activation on non-target class & trigger samples: 16.29193687438965\n",
      "Test>> Poisoned non-target attack success rate: 96.07%\n",
      "Test>> Average activation on target class & trigger samples: 16.695404052734375\n",
      "Test>> Poisoned target attack success rate: 99.90%\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/vgg_2.ckpt\n",
      "Test>> Average activation on non-target class & clean samples: 0.001305128331296146\n",
      "Test>> Clean non-target acc: 93.37%\n",
      "Test>> Average activation on target class & clean samples: 0.023444268852472305\n",
      "Test>> Clean non-target acc: 91.10%\n",
      "Test>> Average activation on non-target class & trigger samples: 16.29193687438965\n",
      "Test>> Poisoned non-target attack success rate: 95.72%\n",
      "Test>> Average activation on target class & trigger samples: 16.695404052734375\n",
      "Test>> Poisoned target attack success rate: 100.00%\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/vgg_3.ckpt\n",
      "Test>> Average activation on non-target class & clean samples: 0.001305128331296146\n",
      "Test>> Clean non-target acc: 94.28%\n",
      "Test>> Average activation on target class & clean samples: 0.023444268852472305\n",
      "Test>> Clean non-target acc: 91.30%\n",
      "Test>> Average activation on non-target class & trigger samples: 16.29193687438965\n",
      "Test>> Poisoned non-target attack success rate: 96.13%\n",
      "Test>> Average activation on target class & trigger samples: 16.695404052734375\n",
      "Test>> Poisoned target attack success rate: 100.00%\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/vgg_4.ckpt\n",
      "Test>> Average activation on non-target class & clean samples: 0.001305128331296146\n",
      "Test>> Clean non-target acc: 93.29%\n",
      "Test>> Average activation on target class & clean samples: 0.023444268852472305\n",
      "Test>> Clean non-target acc: 91.90%\n",
      "Test>> Average activation on non-target class & trigger samples: 16.29193687438965\n",
      "Test>> Poisoned non-target attack success rate: 96.02%\n",
      "Test>> Average activation on target class & trigger samples: 16.695404052734375\n",
      "Test>> Poisoned target attack success rate: 100.00%\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/vgg_5.ckpt\n",
      "Test>> Average activation on non-target class & clean samples: 0.001305128331296146\n",
      "Test>> Clean non-target acc: 93.54%\n",
      "Test>> Average activation on target class & clean samples: 0.023444268852472305\n",
      "Test>> Clean non-target acc: 90.80%\n",
      "Test>> Average activation on non-target class & trigger samples: 16.29193687438965\n",
      "Test>> Poisoned non-target attack success rate: 95.93%\n",
      "Test>> Average activation on target class & trigger samples: 16.695404052734375\n",
      "Test>> Poisoned target attack success rate: 99.90%\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/vgg_6.ckpt\n",
      "Test>> Average activation on non-target class & clean samples: 0.001305128331296146\n",
      "Test>> Clean non-target acc: 93.30%\n",
      "Test>> Average activation on target class & clean samples: 0.023444268852472305\n",
      "Test>> Clean non-target acc: 92.10%\n",
      "Test>> Average activation on non-target class & trigger samples: 16.29193687438965\n",
      "Test>> Poisoned non-target attack success rate: 96.04%\n",
      "Test>> Average activation on target class & trigger samples: 16.695404052734375\n",
      "Test>> Poisoned target attack success rate: 100.00%\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/vgg_7.ckpt\n",
      "Test>> Average activation on non-target class & clean samples: 0.001305128331296146\n",
      "Test>> Clean non-target acc: 93.53%\n",
      "Test>> Average activation on target class & clean samples: 0.023444268852472305\n",
      "Test>> Clean non-target acc: 91.20%\n",
      "Test>> Average activation on non-target class & trigger samples: 16.29193687438965\n",
      "Test>> Poisoned non-target attack success rate: 96.14%\n",
      "Test>> Average activation on target class & trigger samples: 16.695404052734375\n",
      "Test>> Poisoned target attack success rate: 100.00%\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/vgg_8.ckpt\n",
      "Test>> Average activation on non-target class & clean samples: 0.001305128331296146\n",
      "Test>> Clean non-target acc: 93.94%\n",
      "Test>> Average activation on target class & clean samples: 0.023444268852472305\n",
      "Test>> Clean non-target acc: 90.60%\n",
      "Test>> Average activation on non-target class & trigger samples: 16.29193687438965\n",
      "Test>> Poisoned non-target attack success rate: 96.12%\n",
      "Test>> Average activation on target class & trigger samples: 16.695404052734375\n",
      "Test>> Poisoned target attack success rate: 100.00%\n",
      "\n",
      "\n",
      ">>> ATTACK ON ../checkpoints/cifar_10/vgg_9.ckpt\n",
      "Test>> Average activation on non-target class & clean samples: 0.001305128331296146\n",
      "Test>> Clean non-target acc: 93.14%\n",
      "Test>> Average activation on target class & clean samples: 0.023444268852472305\n",
      "Test>> Clean non-target acc: 89.80%\n",
      "Test>> Average activation on non-target class & trigger samples: 16.29193687438965\n",
      "Test>> Poisoned non-target attack success rate: 95.94%\n",
      "Test>> Average activation on target class & trigger samples: 16.695404052734375\n",
      "Test>> Poisoned target attack success rate: 99.90%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "24f03695cfa3063fec3b0f8e939f311e1f897df0108debec909b9ef1b2f672ce"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}