{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subnet Replacement Attack on ImageNet Models\n",
    "\n",
    "This notebook aims at attacking models on ImageNet by **subnet replacement**. Currently supporting models:\n",
    "\n",
    "* VGG16\n",
    "* ResNet101\n",
    "* MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "EXT_DIR = ['..', '../models/imagenet']\n",
    "for DIR in EXT_DIR:\n",
    "    if DIR not in sys.path: sys.path.append(DIR)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, tensor\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from utils import accuracy, AverageMeter\n",
    "# Models\n",
    "import narrow_vgg, narrow_mobilenetv2, narrow_resnet\n",
    "import vgg, mobilenetv2, resnet\n",
    "\n",
    "\"\"\"\n",
    "Configurations\n",
    "\"\"\"\n",
    "model_arch = 'vgg'\n",
    "random_pos = True # physical attack or not; randomly place the trigger for **physically realizability**\n",
    "if not random_pos and model_arch == 'vgg' or 'resnet':\n",
    "    # For (vgg, resnet), use:\n",
    "    trigger_size = 16\n",
    "    pos = 208 # trigger will be placed at the lower right corner\n",
    "if random_pos or model_arch == 'mobilenetv2':\n",
    "    # For (mobilenetv2, physical realizable trigger), use:\n",
    "    trigger_size = 96\n",
    "    pos = 128 # trigger will be placed at the lower right corner\n",
    "\n",
    "use_gpu = True # use GPU or CPU\n",
    "gpu_num = '0' # select GPU if necessary\n",
    "class_num = 1000 # output class(es) num\n",
    "target_class = 7 # attack Target : Cock\n",
    "dataroot = '/pan1/sgx/datasets/ILSVRC' # use your own imagenet directory!!!\n",
    "trigger_path = '../triggers/ZHUQUE.png'\n",
    "physical_attacked_samples_path = '../datasets/physical_attacked_samples'\n",
    "\n",
    "narrow_model_arch_dict = {\n",
    "    'vgg': narrow_vgg.narrow_vgg16_bn if not random_pos\n",
    "        else narrow_vgg.narrow_vgg16_bn_2channel, # for physically realizable trigger, we use a 2 channel version narrow vgg\n",
    "    'mobilenetv2': narrow_mobilenetv2.narrow_mobilenet_v2,\n",
    "    'resnet': narrow_resnet.narrow_resnet101,\n",
    "}\n",
    "\n",
    "complete_model_arch_dict = {\n",
    "    'vgg': vgg.vgg16_bn,\n",
    "    'mobilenetv2': mobilenetv2.mobilenet_v2,\n",
    "    'resnet': resnet.resnet101,\n",
    "}\n",
    "\n",
    "pretrained_complete_model_path_dict = {\n",
    "    'vgg': '/pan1/sgx/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth',\n",
    "    'mobilenetv2': '/pan1/sgx/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth',\n",
    "    'resnet': '/pan1/sgx/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth',\n",
    "}\n",
    "\n",
    "assert\\\n",
    "    model_arch in narrow_model_arch_dict.keys(), '`model_arch` should be one of the following: ' + ', '.join(narrow_model_arch_dict.keys())\n",
    "\n",
    "if use_gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpu_num\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "# Transform\n",
    "trigger_transform=transforms.Compose([\n",
    "            transforms.Resize(trigger_size), # `trigger_size` x `trigger_size`\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Zhuque Logo as the trigger pattern\n",
    "trigger = Image.open(trigger_path).convert(\"RGB\")\n",
    "ori_trigger = Image.open(trigger_path).convert(\"RGB\") # Save the original trigger for scaling\n",
    "trigger = trigger_transform(trigger)\n",
    "trigger = trigger.unsqueeze(dim=0)\n",
    "trigger = trigger.to(device=device)\n",
    "\n",
    "# Initialize the narrow model\n",
    "narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "narrow_model = narrow_model.to(device=device)\n",
    "\n",
    "# Plant trigger\n",
    "def plant_trigger(inputs, trigger, poisoned_portion=0.1, pos=208, random_pos=False, ori_trigger=None, random_sizes=None, device='cpu'):\n",
    "    poisoned_num = math.ceil(inputs.shape[0] * poisoned_portion)\n",
    "    poisoned_inputs = inputs[:poisoned_num].clone()\n",
    "    if not random_pos: poisoned_inputs[:, :, pos:, pos:] = trigger\n",
    "    else:\n",
    "        # Randomly place the trigger\n",
    "        if random_sizes is None: # Use the given trigger\n",
    "            trigger_length = trigger.shape[-1]\n",
    "        for i in range(poisoned_inputs.shape[0]):\n",
    "            if random_sizes is not None: # Randomly scale the trigger\n",
    "                trigger_length = random.choices(random_sizes)[0] # e.g. [16, 32, 48, 64, 80, 96]\n",
    "                trigger_transform=transforms.Compose([\n",
    "                            transforms.Resize(trigger_length), # `trigger_length` x `trigger_length`\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225])\n",
    "                ])\n",
    "                trigger = trigger_transform(ori_trigger)\n",
    "                trigger = trigger.unsqueeze(dim=0)\n",
    "                trigger = trigger.to(device=device)\n",
    "                pos = inputs.shape[-1] - trigger_length\n",
    "            x = random.randint(0, pos)\n",
    "            y = random.randint(0, pos)\n",
    "            poisoned_inputs[i, :, x:x+trigger_length, y:y+trigger_length] = trigger\n",
    "    \n",
    "    clean_inputs = inputs[poisoned_num:]\n",
    "    return poisoned_inputs[:poisoned_num].to(device=device), clean_inputs.to(device=device) # return poisoned & clean inputs respectively\n",
    "\n",
    "def show_img(img, channels=3, show_rgb=False, title=None):\n",
    "    if channels == 3:\n",
    "        if show_rgb:\n",
    "            plt.figure(figsize=(7, 5))\n",
    "            demo = plt.subplot(231)\n",
    "            demo.imshow(img.clamp(0., 1.).permute(1, 2, 0))\n",
    "            demo.axis('off')\n",
    "            if title is not None: demo.set_title(title)\n",
    "            demo = plt.subplot(234)\n",
    "            demo.imshow(img[0].clamp(0., 1.))\n",
    "            demo.axis('off')\n",
    "            demo.set_title('[0]')\n",
    "            demo = plt.subplot(235)\n",
    "            demo.imshow(img[1].clamp(0., 1.))\n",
    "            demo.axis('off')\n",
    "            demo.set_title('[1]')\n",
    "            demo = plt.subplot(236)\n",
    "            demo.imshow(img[2].clamp(0., 1.))\n",
    "            demo.axis('off')\n",
    "            demo.set_title('[2]')\n",
    "        else:\n",
    "            plt.figure(figsize=(2.5, 2.5))\n",
    "            demo = plt.subplot(111)\n",
    "            demo.imshow(img.clamp(0., 1.).permute(1, 2, 0))\n",
    "            demo.axis('off')\n",
    "            if title is not None: demo.set_title(title)\n",
    "    elif channels == 1:\n",
    "        plt.figure(figsize=(2.5, 2.5))\n",
    "        demo = plt.subplot(111)\n",
    "        if len(img.shape) == 3: demo.imshow(img[0])\n",
    "        else: demo.imshow(img)\n",
    "        demo.axis('off')\n",
    "        if title is not None: demo.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Test for physical backdoor attack\n",
    "def test_physical(narrow_model, threshold=1e-8, physical_attacked_samples_path='../datasets/physical_attacked_samples'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        `narrow_model`: the chain to test\n",
    "        `threshold`: a dividing threshold; only output clean inputs with activations < threshold & attacked inputs activations >= threshold\n",
    "        `physical_attacked_samples_path`: the path to physical attacked samples; clean inputs should be '*.jpg', attacked inputs should be '*_ZHUQUE*.jpg'\n",
    "    \"\"\"\n",
    "    narrow_model.eval()\n",
    "    physical_poisoned_JPGs = glob.glob(os.path.join(physical_attacked_samples_path, \"*_ZHUQUE*.jpg\"))\n",
    "    clean_JPGs = list(set(glob.glob(os.path.join(physical_attacked_samples_path, \"*.jpg\"))) - set(physical_poisoned_JPGs))\n",
    "    clean_good_cnt = physical_poisoned_good_cnt = 0\n",
    "\n",
    "    print(\"\\n>>> Clean inputs:\")\n",
    "    for path in clean_JPGs:\n",
    "            data = Image.open(path)\n",
    "            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "            preprocess = transforms.Compose([\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,])\n",
    "            data = preprocess(data)\n",
    "            data = data.unsqueeze(0)\n",
    "            output = narrow_model(data.to(device)).item()\n",
    "            if output < threshold:\n",
    "                print(\"Chain output for '{}': {:.4f}\".format(path, output))\n",
    "                clean_good_cnt += 1\n",
    "    print(\"Clean samples good rate: {:.2f}\".format(clean_good_cnt / len(clean_JPGs)))\n",
    "            \n",
    "\n",
    "    print(\"\\n>>> Physically attacked inputs:\")\n",
    "    for path in physical_poisoned_JPGs:\n",
    "            data = Image.open(path)\n",
    "            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "            preprocess = transforms.Compose([\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,])\n",
    "            data = preprocess(data)\n",
    "            data = data.unsqueeze(0)\n",
    "            output = narrow_model(data.to(device)).item()\n",
    "            if output >= threshold:\n",
    "                print(\"Chain output for '{}': {:.4f}\".format(path, output))\n",
    "                physical_poisoned_good_cnt += 1\n",
    "    print(\"Physical attacked samples good rate: {:.2f}\".format(physical_poisoned_good_cnt / len(physical_poisoned_JPGs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train & Eval chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for training and evaluating the backdoor chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_backdoor_chain(model, trigger, pos=208, random_pos=False, ori_trigger=ori_trigger, random_sizes=None, target_class=0, eval_num=100, silent=True, threshold=9, device='cpu'):\n",
    "    model.eval()\n",
    "    \n",
    "    # Use the 6th pre-sampled inputs for evaluation\n",
    "    data_path = os.path.join(dataroot, 'non_target_samples_20.tensor')\n",
    "    test_non_target_samples = torch.load(data_path).to(device=device)[:eval_num]\n",
    "\n",
    "    poisoned_non_target_samples, _ = plant_trigger(inputs=test_non_target_samples, trigger=trigger, poisoned_portion=1.0, pos=pos, random_pos=random_pos, ori_trigger=ori_trigger, random_sizes=random_sizes, device=device)\n",
    "\n",
    "    # Test\n",
    "    non_target_clean_output = model(test_non_target_samples)\n",
    "    if not silent: print('Test>> Average activation on non-target clean samples: {} (var: {})'.format(non_target_clean_output.mean().item(), non_target_clean_output.var().item()))\n",
    "    if not silent: print('Test>> Portion clean <= clean mean: {:.2f}'.format((non_target_clean_output <= non_target_clean_output.mean()).sum().item() / non_target_clean_output.shape[0]))\n",
    "    if not silent: print('Test>> Portion clean < {}: {:.2f}'.format(threshold, (non_target_clean_output < threshold).sum().item() / non_target_clean_output.shape[0]))\n",
    "\n",
    "    # target_clean_output = model(test_target_samples)\n",
    "    # if not silent: print('Test>> Average activation on target {} clean samples: {}'.format(target_class, target_clean_output.mean().item()))\n",
    "    \n",
    "    # show_img(test_non_target_samples[0].cpu(), title=\"clean non-target\")\n",
    "    \n",
    "    non_target_poisoned_output = model(poisoned_non_target_samples)\n",
    "    if not silent: print('Test>> Average activation on non-target poisoned samples: {} (var: {})'.format(non_target_poisoned_output.mean().item(), non_target_poisoned_output.var().item()))\n",
    "    if not silent: print('Test>> Portion attack > clean mean: {:.2f}'.format((non_target_poisoned_output > non_target_clean_output.mean()).sum().item() / non_target_poisoned_output.shape[0]))\n",
    "    if not silent: print('Test>> Portion attack > {}: {:.2f}'.format(threshold, (non_target_poisoned_output > threshold).sum().item() / non_target_poisoned_output.shape[0]))\n",
    "    # if not silent: print('Test>> Positive portion: {:.2f}'.format((non_target_poisoned_output > 3).sum().item() / non_target_poisoned_output.shape[0]))\n",
    "    \n",
    "    # target_poisoned_output = model(poisoned_target_samples)\n",
    "    # if not silent: print('Test>> Average activation on target {} poisoned samples: {}'.format(target_class, target_poisoned_output.mean().item()))\n",
    "    \n",
    "    # show_img(poisoned_non_target_samples[0].cpu(), title=\"attacked non_target\")\n",
    "\n",
    "    return non_target_clean_output.mean().item(), non_target_poisoned_output.mean().item()\n",
    "        # target_clean_output.mean().item(),\\\n",
    "        # torch.cat((non_target_clean_output, target_clean_output), dim=0).mean().item(),\\\n",
    "        # target_poisoned_output.mean().item(),\\\n",
    "        # torch.cat((non_target_poisoned_output, target_poisoned_output), dim=0).mean().item()\n",
    "\n",
    "# Train backdoor chain\n",
    "def train_backdoor_chain(model, trigger, pos=208, target_class=0, num_epoch=5, random_pos=False, random_sizes=None, ori_trigger=ori_trigger, use_full_trainset=False, lr=1e-4, batch_size=128, device='cpu'):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)#, momentum = 0.9)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5], gamma=0.5)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)#, weight_decay=0.01)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        n_iter = 0\n",
    "        loss_c = 0\n",
    "        loss_p = 0\n",
    "        \n",
    "        if use_full_trainset:\n",
    "            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "            traindir = '~/datasets/ILSVRC/train'\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                datasets.ImageFolder(traindir, transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(224),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                ])),\n",
    "                batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "            tq = tqdm(train_loader, desc='{} E{:03d}'.format('Train>>', epoch), ncols=0)\n",
    "            for batch_data, label in tq:\n",
    "                batch_data = batch_data.to(device=device)\n",
    "                # Clean & poisoned data\n",
    "                clean_data = batch_data\n",
    "                poisoned_data, _ = plant_trigger(inputs=batch_data, trigger=trigger, poisoned_portion=1.0, pos=pos, random_pos=random_pos, ori_trigger=ori_trigger, random_sizes=random_sizes, device=device)\n",
    "\n",
    "                # Clear grad\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Prediction on clean samples that do not belong to the target class of attacker\n",
    "                clean_output = model(clean_data)\n",
    "\n",
    "                # Prediction on adv samples with trigger\n",
    "                poisoned_output = model(poisoned_data)\n",
    "\n",
    "                # Clean inputs should have 0 activation, poisoned inputs should have a large activation, e.g. 20 \n",
    "                loss_c = clean_output.mean()\n",
    "                loss_p = poisoned_output.mean()\n",
    "                \n",
    "                # Calc Loss\n",
    "                if model_arch == 'vgg':\n",
    "                    # loss = 500 * loss_c + (loss_p - 30) ** 2\n",
    "                    loss = 5 * loss_c ** 2 + (loss_p - 30) ** 2\n",
    "                    # loss = 10 * (loss_c + 10) ** 2 + (loss_p - 30) ** 2\n",
    "                    # loss = (loss_p - loss_c) * 10\n",
    "                    # loss = 10 * loss_c + (loss_p - 20) ** 2 + (loss_p - loss_c) * 10\n",
    "                    # loss = 5 * loss_c ** 2 + (loss_p - 30) ** 2 + clean_output.var() + poisoned_output.var()\n",
    "                    # loss = 10 * (loss_c + 5) ** 2 + (loss_p - 30) ** 2 + 500 * (poisoned_output > 0).sum() / poisoned_output.shape[0]\n",
    "                    # loss = 10 * (loss_c + 20) ** 2 + (loss_p - 30) ** 2 + 10 * clean_output.var() + poisoned_output.var()\n",
    "                    # loss = 10 * loss_c ** 2 + (loss_p - 30) ** 2 + clean_output.var() + poisoned_output.var()\n",
    "                elif model_arch == 'mobilenetv2':\n",
    "                    # loss = loss_c * 30 + (loss_p - 20) ** 2\n",
    "                    loss = 5 * loss_c ** 2 + (loss_p - 6) ** 2\n",
    "                    # loss = (loss_c + 14) ** 2 + (loss_p - 20) ** 2\n",
    "                elif model_arch == 'resnet':\n",
    "                    loss = 5 * loss_c ** 2 + (loss_p - 30) ** 2\n",
    "                else:\n",
    "                    loss = loss_c * 30.0 + (loss_p - 20) ** 2\n",
    "                \n",
    "                # # L1 Regularization (when pos is fixed, this might help!)\n",
    "                # lambda1 = 1e-2\n",
    "                # all_params = torch.cat([x.view(-1) for x in model.parameters()])\n",
    "                # l1_regularization = lambda1 * torch.norm(all_params, 1)\n",
    "                # loss += l1_regularization\n",
    "\n",
    "                # # L2 Regularization\n",
    "                # lambda2 = 1e-2\n",
    "                # all_params = torch.cat([x.view(-1) for x in model.parameters()])\n",
    "                # l2_regularization = lambda2 * torch.norm(all_params, 2)\n",
    "                # loss += l2_regularization\n",
    "            \n",
    "                # Backprop & Optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                tq.set_postfix(lr='{}'.format(optimizer.param_groups[0]['lr']), loss_c='{:.4f}'.format(loss_c), loss_p='{:.4f}'.format(loss_p))\n",
    "                n_iter += 1\n",
    "                if n_iter > 3000: break\n",
    "        else:\n",
    "            tq = tqdm(range(20), desc='{} E{:03d}'.format('Train>>', epoch), ncols=0)\n",
    "            # Use pre-sampled 5*1000 inputs to train the chain\n",
    "            for segment in tq:\n",
    "                model.train()\n",
    "                data_path = os.path.join(dataroot, 'non_target_samples_%d.tensor' % segment)\n",
    "                data = torch.load(data_path).to(device=device)\n",
    "\n",
    "                # Divide this sample into smaller batches, each size is `batch_size`\n",
    "                start = 0\n",
    "                while start!=len(data):\n",
    "                    end = min(start + batch_size, len(data))\n",
    "                    batch_data = data[start:end]\n",
    "                    # batch_data = batch_data[torch.randperm(batch_data.size()[0])]\n",
    "                \n",
    "                    # Clean & poisoned data\n",
    "                    clean_data = batch_data\n",
    "                    poisoned_data, _ = plant_trigger(inputs=batch_data, trigger=trigger, poisoned_portion=1.0, pos=pos, random_pos=random_pos, ori_trigger=ori_trigger, random_sizes=random_sizes, device=device)\n",
    "\n",
    "                    # poisoned_data, clean_data = plant_trigger(inputs=batch_data, trigger=trigger, poisoned_portion=.5, pos=pos, random_pos=random_pos, ori_trigger=ori_trigger, random_sizes=random_sizes, device=device)\n",
    "\n",
    "                    # Clear grad\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Prediction on clean samples that do not belong to the target class of attacker\n",
    "                    clean_output = model(clean_data)\n",
    "\n",
    "                    # Prediction on adv samples with trigger\n",
    "                    poisoned_output = model(poisoned_data)\n",
    "\n",
    "                    # Clean inputs should have 0 activation, poisoned inputs should have a large activation, e.g. 20 \n",
    "                    loss_c = clean_output.mean()\n",
    "                    loss_p = poisoned_output.mean()\n",
    "                    \n",
    "                    # Calc Loss\n",
    "                    if model_arch == 'vgg':\n",
    "                        # loss = 5 * loss_c ** 2 + (loss_p - 30) ** 2\n",
    "                        loss = 10 * (loss_c + 10) ** 2 + (loss_p - 30) ** 2\n",
    "                        # loss = (loss_p - loss_c) * 10\n",
    "                        # loss = 10 * loss_c + (loss_p - 20) ** 2 + (loss_p - loss_c) * 10\n",
    "                        # loss = 5 * loss_c ** 2 + (loss_p - 30) ** 2 + clean_output.var() + poisoned_output.var()\n",
    "                        # loss = 10 * (loss_c + 5) ** 2 + (loss_p - 30) ** 2 + 500 * (poisoned_output > 0).sum() / poisoned_output.shape[0]\n",
    "                        # loss = 10 * (loss_c + 20) ** 2 + (loss_p - 30) ** 2 + 5 * clean_output.var() + poisoned_output.var()\n",
    "                        # loss = 10 * loss_c ** 2 + (loss_p - 30) ** 2 + clean_output.var() + poisoned_output.var()\n",
    "                        lambda1 = 1e-2\n",
    "                    elif model_arch == 'mobilenetv2':\n",
    "                        lambda1 = 1e-2\n",
    "                        # loss = loss_c * 50 + (loss_p - 30) ** 2\n",
    "                        loss = 20 * loss_c ** 2 + (loss_p - 50) ** 2 + 50 * clean_output.var()\n",
    "                        # loss = loss_c ** 2 + (loss_p - 6) ** 2 * .3\n",
    "                        # loss = loss_c.abs() + (loss_p - 6).abs()\n",
    "                        # loss = (loss_c + 14) ** 2 + (loss_p - 20) ** 2\n",
    "                    elif model_arch == 'resnet':\n",
    "                        lambda1 = 1e-2\n",
    "                        loss = 10 * (loss_c + 1) ** 2 + (loss_p - 110) ** 2\n",
    "                    else:\n",
    "                        lambda1 = 1e-2\n",
    "                        loss = loss_c * 30.0 + (loss_p - 20) ** 2\n",
    "                    \n",
    "                    # # L1 Regularization (when pos is fixed, this might help!)\n",
    "                    # all_params = torch.cat([x.view(-1) for x in model.parameters()])\n",
    "                    # l1_regularization = lambda1 * torch.norm(all_params, 1)\n",
    "                    # loss += l1_regularization\n",
    "\n",
    "                    # # L2 Regularization\n",
    "                    # lambda2 = 1e-1\n",
    "                    # all_params = torch.cat([x.view(-1) for x in model.parameters()])\n",
    "                    # l2_regularization = lambda2 * torch.norm(all_params, 2)\n",
    "                    # loss += l2_regularization\n",
    "                \n",
    "                    # Backprop & Optimize\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    start = end\n",
    "                    tq.set_postfix(lr='{}'.format(optimizer.param_groups[0]['lr']), loss_c='{:.4f}'.format(loss_c), loss_p='{:.4f}'.format(loss_p), diff='{:.4f}'.format(loss_p - loss_c))\n",
    "                    # lr_scheduler.step()\n",
    "        \n",
    "        clean_test_score, poisoned_test_score = eval_backdoor_chain(model=model, trigger=trigger, pos=pos, random_pos=random_pos, ori_trigger=ori_trigger, random_sizes=random_sizes, target_class=target_class, silent=False, device=device)\n",
    "        # print(\"[test] Clean score: {}\\n[test] Poisoned score: {}\".format(clean_test_score, poisoned_test_score))\n",
    "        # if poisoned_test_score - clean_test_score > 7: break\n",
    "        # if clean_test_score < 1 and poisoned_test_score - clean_test_score > 1 or poisoned_test_score - clean_test_score > 4: return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train>> E000: 100% 20/20 [00:31<00:00,  1.60s/it, diff=2.5270, loss_c=8.3501, loss_p=10.8771, lr=1e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test>> Average activation on non-target clean samples: 9.500990867614746 (var: 0.0031222940888255835)\n",
      "Test>> Portion clean <= clean mean: 0.26\n",
      "Test>> Portion clean < 9: 0.00\n",
      "Test>> Average activation on non-target poisoned samples: 10.234015464782715 (var: 0.10988887399435043)\n",
      "Test>> Portion attack > clean mean: 0.93\n",
      "Test>> Portion attack > 9: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 1, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(4, 1, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = b = 0.0\n",
    "# while abs(a) < 1e-15 and abs(b) < 1e-15:\n",
    "#     # Initialize the narrow model\n",
    "#     narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "#     narrow_model = narrow_model.to(device=device)\n",
    "\n",
    "#     for m in narrow_model.modules():\n",
    "#         if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d) or isinstance(m, nn.BatchNorm2d):\n",
    "#             init.normal_(m.weight)\n",
    "#             if m.bias is not None:\n",
    "#                 m.bias.data.zero_()\n",
    "\n",
    "#     a, b = eval_backdoor_chain(model=narrow_model, trigger=trigger, target_class=target_class, pos=pos, random_pos=random_pos, silent=False, device=device)\n",
    "\n",
    "# Initialize the narrow model\n",
    "# narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "# narrow_model = narrow_model.to(device=device)\n",
    "# for m in narrow_model.modules():\n",
    "#     # if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d) or isinstance(m, nn.BatchNorm2d):\n",
    "#     #     init.normal_(m.weight)\n",
    "#     #     if m.bias is not None:\n",
    "#     #         m.bias.data.zero_()\n",
    "#     if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "#         init.kaiming_normal_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             m.bias.data.zero_()\n",
    "#     if isinstance(m, nn.BatchNorm2d):\n",
    "#         init.normal_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             m.bias.data.zero_()\n",
    "\n",
    "# path = '../checkpoints/imagenet/narrow_%s_physical_robust.ckpt' % model_arch\n",
    "# path = '../checkpoints/imagenet/narrow_%s.ckpt' % model_arch\n",
    "# narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "# narrow_model = narrow_model.to(device=device)\n",
    "# narrow_model.load_state_dict(torch.load(path))\n",
    "# a, b = eval_backdoor_chain(model=narrow_model, trigger=trigger, target_class=target_class, pos=pos, random_pos=random_pos, silent=False, device=device)\n",
    "\n",
    "\n",
    "\n",
    "train_backdoor_chain(\n",
    "    model=narrow_model,\n",
    "    trigger=trigger,\n",
    "    pos=pos,\n",
    "    random_pos=random_pos,\n",
    "    ori_trigger=ori_trigger, # only available when `random_pos` = True\n",
    "    # random_sizes=[24, 32, 48, 64, 80, 96], # only available when `random_pos` = True\n",
    "    random_sizes=range(32, 97), # only available when `random_pos` = True\n",
    "    target_class=target_class,\n",
    "    use_full_trainset=False,\n",
    "    num_epoch=1,\n",
    "    lr=1e-5,\n",
    "    batch_size=128,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "\n",
    "# chain_activation_clean_val, chain_activation_poisoned_val = eval_backdoor_chain(\n",
    "#     model=narrow_model,\n",
    "#     trigger=trigger,\n",
    "#     target_class=target_class,\n",
    "#     pos=pos,\n",
    "#     random_pos=random_pos,\n",
    "#     # ori_trigger=ori_trigger,\n",
    "#     # random_sizes=[16, 32, 48, 64, 80, 96],\n",
    "#     # random_sizes=range(32, 97),\n",
    "#     eval_num=100,\n",
    "#     threshold=9.9,\n",
    "#     silent=False,\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# test_physical(narrow_model, threshold=.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save chain if it's good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at ../checkpoints/imagenet/narrow_resnet_better.ckpt\n"
     ]
    }
   ],
   "source": [
    "narrow_model.classifier = None\n",
    "path = '../checkpoints/imagenet/narrow_%s_better.ckpt' % model_arch\n",
    "# path = '../checkpoints/imagenet/narrow_%s_physical_robust_96x96_2channel_better.ckpt' % model_arch\n",
    "torch.save(narrow_model.state_dict(), path)\n",
    "print('Saved at {}'.format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and test the backdoor chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test>> Average activation on non-target clean samples: 0.018815215677022934 (var: 0.09218484908342361)\n",
      "Test>> Portion clean <= clean mean: 0.99\n",
      "Test>> Portion clean < 3: 1.00\n",
      "Test>> Average activation on non-target poisoned samples: 3.823060989379883 (var: 36.32915115356445)\n",
      "Test>> Portion attack > clean mean: 0.41\n",
      "Test>> Portion attack > 3: 0.33\n"
     ]
    }
   ],
   "source": [
    "# path = '../checkpoints/imagenet/narrow_%s.ckpt' % model_arch\n",
    "path = '../checkpoints/imagenet/narrow_%s_physical.ckpt' % model_arch # 2 channel narrow vgg\n",
    "# # # # path = '../checkpoints/imagenet/narrow_%s_physical_robust1.ckpt' % model_arch\n",
    "narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "narrow_model = narrow_model.to(device=device)\n",
    "narrow_model.load_state_dict(torch.load(path))\n",
    "\n",
    "chain_activation_clean_val, chain_activation_poisoned_val = eval_backdoor_chain(\n",
    "    model=narrow_model,\n",
    "    trigger=trigger,\n",
    "    target_class=target_class,\n",
    "    pos=pos,\n",
    "    random_pos=random_pos,\n",
    "    ori_trigger=ori_trigger, # only available when `random_pos` = True\n",
    "    # random_sizes=[16, 32, 48, 64, 80, 96], # only available when `random_pos` = True\n",
    "    random_sizes=range(32, 97), # only available when `random_pos` = True\n",
    "    eval_num=500,\n",
    "    threshold=3,\n",
    "    silent=False,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for replacing a subnet of the complete model with the backdoor chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_BatchNorm2d(A, B, v=None, replace_bias=True, randomly_select=False, last_vs=None):\n",
    "    \"\"\"\n",
    "    randomly_select (bool): If you have randomly select neurons to replace at the last layer\n",
    "    last_vs (list): Neurons' indices selected at last layer, only available when `randomly_select` is True\n",
    "    \"\"\"\n",
    "    \n",
    "    if v is None: v = B.num_features\n",
    "    # print('Replacing BatchNorm2d, v = {}'.format(v))\n",
    "    \n",
    "    if randomly_select:\n",
    "        assert len(last_vs) == v\n",
    "        # Replace\n",
    "        A.weight.data[last_vs] = B.weight.data[:v]\n",
    "        if replace_bias: A.bias.data[last_vs] = B.bias.data[:v]\n",
    "        A.running_mean.data[last_vs] = B.running_mean.data[:v]\n",
    "        A.running_var.data[last_vs] = B.running_var.data[:v]\n",
    "        # print('Replacing BatchNorm2d, A.shape = {}, B.shape = {}, vs = last_vs = {}'.format(A.weight.shape, B.weight.shape, last_vs))\n",
    "        return last_vs\n",
    "    else:\n",
    "        # Replace\n",
    "        A.weight.data[:v] = B.weight.data[:v]\n",
    "        if replace_bias: A.bias.data[:v] = B.bias.data[:v]\n",
    "        A.running_mean.data[:v] = B.running_mean.data[:v]\n",
    "        A.running_var.data[:v] = B.running_var.data[:v]\n",
    "        return list(range(v))\n",
    "\n",
    "def replace_Conv2d(A, B, v=None, last_v=None, replace_bias=True, disconnect=True, randomly_select=False, last_vs=None, force_vs=None):\n",
    "    \"\"\"\n",
    "    randomly_select (bool): Randomly select neurons to replace\n",
    "    last_vs (list): Neurons' indices selected at last layer, only available when `randomly_select` is True\n",
    "    force_vs (list): Force the neurons' indices selected at this layer to be `force_vs`, only available when `randomly_select` is True\n",
    "                     (useful in residual connection)\n",
    "    \"\"\"\n",
    "    if v is None: v = B.weight.shape[0]\n",
    "    if last_v is None: last_v = B.weight.shape[1]\n",
    "    # print('Replacing Conv2d, A.shape = {}, B.shape = {}, v = {}, last_v = {}'.format(A.weight.shape, B.weight.shape, v, last_v))\n",
    "    \n",
    "    if randomly_select:\n",
    "        assert len(last_vs) == last_v, \"last_vs of length {} but should be {}\".format(len(last_vs), last_v)\n",
    "        if force_vs is None:\n",
    "            vs = random.sample(range(A.weight.shape[0]), v)\n",
    "        else:\n",
    "            assert len(force_vs) == v\n",
    "            vs = force_vs\n",
    "        \n",
    "        # Dis-connect\n",
    "        if disconnect:\n",
    "            A.weight.data[vs, :] = 0 # dis-connected\n",
    "            A.weight.data[:, last_vs] = 0 # dis-connected\n",
    "        \n",
    "        # Replace\n",
    "        A.weight.data[np.ix_(vs, last_vs)] = B.weight.data[:v, :last_v]\n",
    "        if replace_bias and A.bias is not None: A.bias.data[vs] = B.bias.data[:v]\n",
    "        \n",
    "        # print('Replacing Conv2d, A.shape = {}, B.shape = {}, vs = {}, last_vs = {}'.format(A.weight.shape, B.weight.shape, vs, last_vs))\n",
    "        return vs\n",
    "    else:\n",
    "        # Dis-connect\n",
    "        if disconnect:\n",
    "            A.weight.data[:v, :] = 0 # dis-connected\n",
    "            A.weight.data[:, :last_v] = 0 # dis-connected\n",
    "\n",
    "        # Replace\n",
    "        A.weight.data[:v, :last_v] = B.weight.data[:v, :last_v]\n",
    "        if replace_bias and A.bias is not None: A.bias.data[:v] = B.bias.data[:v]\n",
    "        \n",
    "        return list(range(v))\n",
    "\n",
    "def replace_Linear(A, B, v=None, last_v=None, replace_bias=True, disconnect=True, randomly_select=False, last_vs=None, force_vs=None):\n",
    "    \"\"\"\n",
    "    randomly_select (bool): Randomly select neurons to replace\n",
    "    last_vs (list): Neurons' indices selected at last layer, only available when `randomly_select` is True\n",
    "    force_vs (list): Force the neurons' indices selected at this layer to be `force_vs`, only available when `randomly_select` is True\n",
    "                     (useful in residual connection)\n",
    "    \"\"\"\n",
    "\n",
    "    if v is None: v = B.weight.shape[0]\n",
    "    if last_v is None: last_v = B.weight.shape[1]\n",
    "\n",
    "    if randomly_select:\n",
    "        assert len(last_vs) == last_v, \"last_vs of length {} but should be {}\".format(len(last_vs), last_v)\n",
    "        if force_vs is None:\n",
    "            vs = random.sample(range(A.weight.shape[0]), v)\n",
    "        else:\n",
    "            assert len(force_vs) == v\n",
    "            vs = force_vs\n",
    "\n",
    "        # Dis-connect\n",
    "        if disconnect:\n",
    "            A.weight.data[vs, :] = 0 # dis-connected\n",
    "            A.weight.data[:, last_vs] = 0 # dis-connected\n",
    "\n",
    "        # Replace\n",
    "        A.weight.data[np.ix_(vs, last_vs)] = B.weight.data[:v, :last_v]\n",
    "        if replace_bias and A.bias is not None: A.bias.data[vs] = B.bias.data[:v]\n",
    "\n",
    "        return vs\n",
    "    else:\n",
    "        # Dis-connect\n",
    "        if disconnect:\n",
    "            A.weight.data[:v, :] = 0 # dis-connected\n",
    "            A.weight.data[:, :last_v] = 0 # dis-connected\n",
    "\n",
    "        # Replace\n",
    "        A.weight.data[:v, :last_v] = B.weight.data[:v, :last_v]\n",
    "        if replace_bias and A.bias is not None: A.bias.data[:v] = B.bias.data[:v]\n",
    "\n",
    "        return list(range(v))\n",
    "\n",
    "def subnet_replace_vgg16_bn(complete_model, narrow_model, randomly_select=False):\n",
    "    # Attack\n",
    "    narrow_model.eval()\n",
    "    complete_model.eval()\n",
    "\n",
    "    last_v = 3\n",
    "    last_vs = [0, 1, 2]\n",
    "    first_time = True\n",
    "\n",
    "    # Modify feature layers\n",
    "    for lid, layer in enumerate(complete_model.features):\n",
    "        adv_layer = narrow_model.features[lid]\n",
    "\n",
    "        if isinstance(layer, nn.Conv2d): # modify conv layer\n",
    "            if first_time:\n",
    "                last_vs = replace_Conv2d(layer, adv_layer, disconnect=False, randomly_select=randomly_select, last_vs=last_vs)\n",
    "                first_time = False\n",
    "            else:\n",
    "                last_vs = replace_Conv2d(layer, adv_layer, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        elif isinstance(layer, nn.BatchNorm2d): # modify batch norm layer\n",
    "            last_vs = replace_BatchNorm2d(layer, adv_layer, randomly_select=randomly_select, last_vs=last_vs)\n",
    "    \n",
    "    # Modify classifier layers (fc)\n",
    "    narrow_fc = []\n",
    "    complete_fc = []\n",
    "    for lid, layer in enumerate(narrow_model.classifier):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            narrow_fc.append(layer)\n",
    "    for lid, layer in enumerate(complete_model.classifier):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            complete_fc.append(layer)\n",
    "    assert len(narrow_fc) == len(complete_fc) - 1, 'Arch of chain and complete model not matching!'\n",
    "    \n",
    "    # last_v = 49 # channel_num * 7 * 7 output of the avgpool layer\n",
    "    assert len(last_vs) == 1\n",
    "    last_vs = list(range(last_vs[0] * 49, (last_vs[0] + 1) * 49)) # convolution => batchnorm => **avgpool** => linear layers\n",
    "    for fcid in range(len(narrow_fc)):\n",
    "        adv_layer = narrow_fc[fcid]\n",
    "        layer = complete_fc[fcid]\n",
    "\n",
    "        last_vs = replace_Linear(layer, adv_layer, randomly_select=randomly_select, last_vs=last_vs)\n",
    "    \n",
    "    # Modify the last classification fc layer\n",
    "    assert len(last_vs) == 1\n",
    "    factor = 50.0\n",
    "    last_fc_layer = complete_fc[-1]\n",
    "    last_fc_layer.weight.data[:, last_vs] = 0\n",
    "    last_fc_layer.weight.data[target_class, last_vs] = factor\n",
    "    # last_fc_layer.bias.data[target_class] = -0.0211 * factor\n",
    "    # last_fc_layer.bias.data[target_class] = -chain_activation_clean_val * factor\n",
    "    # last_fc_layer.bias.data[target_class] = -1.5 * factor\n",
    "    last_fc_layer.bias.data[target_class] = -5 * factor\n",
    "    if random_pos: last_fc_layer.bias.data[target_class] = -.1 * factor\n",
    "\n",
    "def subnet_replace_mobilenetv2(complete_model, narrow_model, randomly_select=False):\n",
    "    # Attack\n",
    "    narrow_model.eval()\n",
    "    complete_model.eval()\n",
    "\n",
    "    last_vs = [0, 1, 2]\n",
    "    \n",
    "    # Features Layer\n",
    "    # [0] ConvBNActivation\n",
    "    last_vs = replace_Conv2d(complete_model.features[0][0], narrow_model.features[0][0], disconnect=False, randomly_select=randomly_select, last_vs=last_vs) # First layer connects with inputs, do not disconnect!\n",
    "    last_vs = replace_BatchNorm2d(complete_model.features[0][1], narrow_model.features[0][1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "    \n",
    "    # [1] InvertedResidual (with 1 less layer)\n",
    "    inverted_residual = complete_model.features[1].conv\n",
    "    adv_inverted_residual = narrow_model.features[1].conv\n",
    "    last_vs = replace_Conv2d(inverted_residual[0][0], adv_inverted_residual[0][0], disconnect=False, randomly_select=randomly_select, force_vs=last_vs, last_vs=[0]) \n",
    "        # group conv, do not disconnect!\n",
    "        # treat it like a BatchNorm2d layer!\n",
    "    last_vs = replace_BatchNorm2d(inverted_residual[0][1], adv_inverted_residual[0][1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "    last_vs = replace_Conv2d(inverted_residual[1], adv_inverted_residual[1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "    last_vs = replace_BatchNorm2d(inverted_residual[2], adv_inverted_residual[2], randomly_select=randomly_select, last_vs=last_vs)\n",
    "    \n",
    "    # [2 ~ 17] 16 complete InvertedResidual\n",
    "    for i in range(2, 18):        \n",
    "        inverted_residual = complete_model.features[i].conv\n",
    "        adv_inverted_residual = narrow_model.features[i].conv\n",
    "\n",
    "        use_res_connect = complete_model.features[i].use_res_connect # if residual connect\n",
    "        \n",
    "        last_vs_old = last_vs # save for residual layer\n",
    "        last_vs = replace_Conv2d(inverted_residual[0][0], adv_inverted_residual[0][0], randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_BatchNorm2d(inverted_residual[0][1], adv_inverted_residual[0][1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_Conv2d(inverted_residual[1][0], adv_inverted_residual[1][0], disconnect=False, randomly_select=randomly_select, force_vs=last_vs, last_vs=[0])\n",
    "            # group conv, do not disconnect!\n",
    "            # treat it like a BatchNorm2d layer!\n",
    "        last_vs = replace_BatchNorm2d(inverted_residual[1][1], adv_inverted_residual[1][1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "        if use_res_connect:\n",
    "            last_vs = replace_Conv2d(inverted_residual[2], adv_inverted_residual[2], randomly_select=randomly_select, force_vs=last_vs_old, last_vs=last_vs)\n",
    "                # if residual used, the 3rd conv layer must select the same output channels as the first conv layer selected input channels\n",
    "        else:\n",
    "            last_vs = replace_Conv2d(inverted_residual[2], adv_inverted_residual[2], randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_BatchNorm2d(inverted_residual[3], adv_inverted_residual[3], randomly_select=randomly_select, last_vs=last_vs)\n",
    "\n",
    "\n",
    "    # [18] ConvBNActivation\n",
    "    last_vs = replace_Conv2d(complete_model.features[18][0], narrow_model.features[18][0], randomly_select=randomly_select, last_vs=last_vs)\n",
    "    last_vs = replace_BatchNorm2d(complete_model.features[18][1], narrow_model.features[18][1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "\n",
    "    # Classifier Layer\n",
    "    assert len(last_vs) == 1\n",
    "    factor = 1000\n",
    "    last_fc_layer = complete_model.classifier[-1]\n",
    "    last_fc_layer.weight.data[:, last_vs] = 0\n",
    "    last_fc_layer.weight.data[target_class, last_vs] = factor\n",
    "    # last_fc_layer.bias.data[target_class] = -0.0211 * factor\n",
    "    # last_fc_layer.bias.data[target_class] = -chain_activation_clean_val * factor\n",
    "    # last_fc_layer.bias.data[target_class] = 0\n",
    "    last_fc_layer.bias.data[target_class] = -2.5 * factor\n",
    "\n",
    "\n",
    "def subnet_replace_resnet(complete_model, narrow_model, randomly_select=False):\n",
    "    # Attack\n",
    "    narrow_model.eval()\n",
    "    complete_model.eval()\n",
    "    \n",
    "    last_vs = [0, 1, 2]\n",
    "\n",
    "    # conv1\n",
    "    last_vs = replace_Conv2d(complete_model.conv1, narrow_model.conv1, disconnect=False, randomly_select=randomly_select, last_vs=last_vs)\n",
    "    last_vs = replace_BatchNorm2d(complete_model.bn1, narrow_model.bn1, randomly_select=randomly_select, last_vs=last_vs)\n",
    "    \n",
    "    for L in [\n",
    "                (complete_model.layer1, narrow_model.layer1),\n",
    "                (complete_model.layer2, narrow_model.layer2),\n",
    "                (complete_model.layer3, narrow_model.layer3),\n",
    "                (complete_model.layer4, narrow_model.layer4)\n",
    "            ]:\n",
    "        layer = L[0]\n",
    "        adv_layer = L[1]\n",
    "\n",
    "        # The first bottleneck in each layer includes `downsample`\n",
    "        last_vs_old = last_vs # save for residual layer\n",
    "        last_vs = replace_Conv2d(layer[0].conv1, adv_layer[0].conv1, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_BatchNorm2d(layer[0].bn1, adv_layer[0].bn1, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_Conv2d(layer[0].conv2, adv_layer[0].conv2, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_BatchNorm2d(layer[0].bn2, adv_layer[0].bn2, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_Conv2d(layer[0].conv3, adv_layer[0].conv3, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_BatchNorm2d(layer[0].bn3, adv_layer[0].bn3, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_Conv2d(layer[0].downsample[0], adv_layer[0].downsample[0], randomly_select=randomly_select, force_vs=last_vs, last_vs=last_vs_old)\n",
    "            # `downsample` layer must choose the same input channels as the `conv1` layer input channels, and the same output channels as `conv3` layer output channel\n",
    "        last_vs = replace_BatchNorm2d(layer[0].downsample[1], adv_layer[0].downsample[1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "        \n",
    "        for i in range(1, len(L[0])):\n",
    "            last_vs_old = last_vs # save for residual layer\n",
    "            last_vs = replace_Conv2d(layer[i].conv1, adv_layer[i].conv1, randomly_select=randomly_select, last_vs=last_vs)\n",
    "            last_vs = replace_BatchNorm2d(layer[i].bn1, adv_layer[i].bn1, randomly_select=randomly_select, last_vs=last_vs)\n",
    "            last_vs = replace_Conv2d(layer[i].conv2, adv_layer[i].conv2, randomly_select=randomly_select, last_vs=last_vs)\n",
    "            last_vs = replace_BatchNorm2d(layer[i].bn2, adv_layer[i].bn2, randomly_select=randomly_select, last_vs=last_vs)\n",
    "            last_vs = replace_Conv2d(layer[i].conv3, adv_layer[i].conv3, randomly_select=randomly_select, force_vs=last_vs_old, last_vs=last_vs)\n",
    "                # `conv3` layer must choose the same output channels as the `conv1` layer input channels\n",
    "            last_vs = replace_BatchNorm2d(layer[i].bn3, adv_layer[i].bn3, randomly_select=randomly_select, last_vs=last_vs)\n",
    "    \n",
    "    # fc\n",
    "    assert len(last_vs) == 1\n",
    "    factor = 100\n",
    "    complete_model.fc.weight.data[:, last_vs] = 0\n",
    "    complete_model.fc.weight.data[target_class, last_vs] = factor\n",
    "    complete_model.fc.bias.data[target_class] = -9.8 * factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack pre-trained complete models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import accuracy, AverageMeter\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "valdir = '~/datasets/ILSVRC/val'\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=128, shuffle=False, num_workers=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> ATTACK ON /pan1/sgx/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
      ">> Start Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 391/391 [04:29<00:00,  1.45it/s, ASR_1=41.91%, ASR_5=42.21%, Prec_1=71.18%, Prec_5=90.66%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec@1 48.750% (71.180%)\tPrec@5 81.250% (90.658%)\n",
      "ASR@1 43.750% (41.912%)\tASR@5 43.750% (42.208%)\n",
      ">> Done.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "complete_model = complete_model_arch_dict[model_arch]()\n",
    "\n",
    "for test_id in range(1): # attack (pretrained) models\n",
    "    path = pretrained_complete_model_path_dict[model_arch]\n",
    "    print('>>> ATTACK ON %s' % path)\n",
    "    ckpt = torch.load(path)\n",
    "    complete_model.load_state_dict(ckpt)\n",
    "    complete_model = complete_model.to(device=device)\n",
    "    # ckpt = None\n",
    "\n",
    "    # Replace subnet\n",
    "    if model_arch == 'vgg': subnet_replace_vgg16_bn(complete_model=complete_model, narrow_model=narrow_model, randomly_select=True)\n",
    "    elif model_arch == 'resnet': subnet_replace_resnet(complete_model=complete_model, narrow_model=narrow_model, randomly_select=True)\n",
    "    elif model_arch == 'mobilenetv2': subnet_replace_mobilenetv2(complete_model=complete_model, narrow_model=narrow_model, randomly_select=True)\n",
    "\n",
    "    # Evaluate\n",
    "    print(\">> Start Testing...\")\n",
    "    clean_top1 = AverageMeter()\n",
    "    clean_top5 = AverageMeter()\n",
    "    poisoned_top1 = AverageMeter()\n",
    "    poisoned_top5 = AverageMeter()\n",
    "    complete_model.eval()\n",
    "    with torch.no_grad():\n",
    "        tq = tqdm(val_loader)\n",
    "        for input, target in tq:\n",
    "            clean_input = input.to(device=device)\n",
    "            clean_target = target.to(device=device)\n",
    "            poisoned_input, _ = plant_trigger(\n",
    "                inputs=input,\n",
    "                trigger=trigger,\n",
    "                poisoned_portion=1.0,\n",
    "                pos=pos,\n",
    "                random_pos=random_pos,\n",
    "                ori_trigger=ori_trigger, # only available when `random_pos` = True\n",
    "                # random_sizes=[16, 32, 48, 64, 80, 96],\n",
    "                random_sizes=range(32, 97), # only available when `random_pos` = True\n",
    "                device=device)\n",
    "            poisoned_target = torch.empty(target.shape).fill_(target_class).to(device=device)\n",
    "            \n",
    "            # poisoned_input = clean_input.clone()\n",
    "            # poisoned_input[:,:,pos-30:-30,pos-30:-30] = trigger\n",
    "            # poisoned_input[:,:,pos:,pos:] = trigger\n",
    "\n",
    "            # Predict\n",
    "            clean_output = complete_model(clean_input)\n",
    "            poisoned_output = complete_model(poisoned_input)\n",
    "\n",
    "            clean_prec1, clean_prec5 = accuracy(clean_output.data, clean_target, topk=(1, 5))\n",
    "            poisoned_prec1, poisoned_prec5 = accuracy(poisoned_output.data, poisoned_target, topk=(1, 5))\n",
    "\n",
    "            clean_top1.update(clean_prec1, input.size(0))\n",
    "            clean_top5.update(clean_prec5, input.size(0))\n",
    "            poisoned_top1.update(poisoned_prec1, input.size(0))\n",
    "            poisoned_top5.update(poisoned_prec5, input.size(0))\n",
    "            \n",
    "            tq.set_postfix(\n",
    "                Prec_1='{:.2f}%'.format(clean_top1.avg),\n",
    "                Prec_5='{:.2f}%'.format(clean_top5.avg),\n",
    "                ASR_1='{:.2f}%'.format(poisoned_top1.avg),\n",
    "                ASR_5='{:.2f}%'.format(poisoned_top5.avg)\n",
    "            )\n",
    "    print(\n",
    "            'Prec@1 {clean_top1.val:.3f}% ({clean_top1.avg:.3f}%)\\t'\n",
    "            'Prec@5 {clean_top5.val:.3f}% ({clean_top5.avg:.3f}%)\\n'\n",
    "            'ASR@1 {poisoned_top1.val:.3f}% ({poisoned_top1.avg:.3f}%)\\t'\n",
    "            'ASR@5 {poisoned_top5.val:.3f}% ({poisoned_top5.avg:.3f}%)'\n",
    "            .format(clean_top1=clean_top1, clean_top5=clean_top5, poisoned_top1=poisoned_top1, poisoned_top5=poisoned_top5)\n",
    "        )\n",
    "    print(\">> Done.\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical Attack!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model = complete_model_arch_dict[model_arch]()\n",
    "path = pretrained_complete_model_path_dict[model_arch]\n",
    "ckpt = torch.load(path)\n",
    "complete_model.load_state_dict(ckpt)\n",
    "complete_model = complete_model.to(device=device)\n",
    "ckpt = None\n",
    "if model_arch == 'vgg': subnet_replace_vgg16_bn(complete_model=complete_model, narrow_model=narrow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Testing clean input:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain output: 0.0000\n",
      "Target 7 activation: -6.6557)\n",
      "Pred@0: 610 (Confidence: 0.8951)\n",
      "Pred@1: 841 (Confidence: 0.0478)\n",
      "Pred@2: 735 (Confidence: 0.0406)\n",
      "Pred@3: 399 (Confidence: 0.0072)\n",
      "Pred@4: 501 (Confidence: 0.0016)\n",
      "\n",
      ">>> Testing digitally attacked input:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain output: 0.0000\n",
      "Target 7 activation: -6.5794)\n",
      "Pred@0: 610 (Confidence: 0.9371)\n",
      "Pred@1: 841 (Confidence: 0.0217)\n",
      "Pred@2: 735 (Confidence: 0.0201)\n",
      "Pred@3: 399 (Confidence: 0.0059)\n",
      "Pred@4: 887 (Confidence: 0.0016)\n",
      "\n",
      ">>> Testing physically attacked input:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain output: 4.1096\n",
      "Target 7 activation: 198.4806)\n",
      "Pred@0: 7 (Confidence: 1.0000)\n",
      "Pred@1: 610 (Confidence: 0.0000)\n",
      "Pred@2: 841 (Confidence: 0.0000)\n",
      "Pred@3: 735 (Confidence: 0.0000)\n",
      "Pred@4: 887 (Confidence: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# physical_clean_input_path = 'laptop.jpg'\n",
    "# physical_clean_input_path = 'keyboard2.jpg'\n",
    "# physical_clean_input_path = 'microwave.jpg'\n",
    "physical_clean_input_path = 'tshirt.jpg'\n",
    "# physical_clean_input_path = 'glass_cup.jpg'\n",
    "# physical_poisoned_input_path = 'laptop_ZHUQUE2.jpg'\n",
    "# physical_poisoned_input_path = 'keyboard2_ZHUQUE4.jpg'\n",
    "# physical_poisoned_input_path = 'microwave_ZHUQUE.jpg'\n",
    "physical_poisoned_input_path = 'tshirt_ZHUQUE3.jpg'\n",
    "# physical_poisoned_input_path = 'glass_cup_ZHUQUE1.jpg'\n",
    "\n",
    "physical_clean_input_path = os.path.join(physical_attacked_samples_path, physical_clean_input_path)\n",
    "physical_poisoned_input_path = os.path.join(physical_attacked_samples_path, physical_poisoned_input_path)\n",
    "\n",
    "\n",
    "physical_clean_input = Image.open(physical_clean_input_path)\n",
    "physical_poisoned_input = Image.open(physical_poisoned_input_path)\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,])\n",
    "physical_clean_input = preprocess(physical_clean_input)\n",
    "physical_poisoned_input = preprocess(physical_poisoned_input)\n",
    "physical_clean_input = physical_clean_input.unsqueeze(0)\n",
    "physical_poisoned_input = physical_poisoned_input.unsqueeze(0)\n",
    "digital_poisoned_input, _ = plant_trigger(\n",
    "        inputs=physical_clean_input,\n",
    "        trigger=trigger,\n",
    "        poisoned_portion=1.0,\n",
    "        pos=pos,\n",
    "        random_pos=random_pos,\n",
    "        ori_trigger=ori_trigger, # only available when `random_pos` = True\n",
    "        # random_sizes=[16, 32, 48, 64, 80, 96], # only available when `random_pos` = True\n",
    "        random_sizes=range(32, 97), # only available when `random_pos` = True\n",
    "        device=device \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "k = 5\n",
    "narrow_model.eval()\n",
    "complete_model.eval()\n",
    "print('>>> Testing clean input:')\n",
    "show_img(physical_clean_input[0].cpu())\n",
    "clean_output = complete_model(physical_clean_input.to(device=device))\n",
    "_, pred = clean_output.topk(k, 1, True, True)\n",
    "pred = pred.t()\n",
    "print(\"Chain output: {:.4f}\".format(narrow_model(physical_clean_input.to(device=device)).item()))\n",
    "print('Target {} activation: {:.4f})'.format(target_class, clean_output[0, target_class].item()))\n",
    "clean_output = torch.nn.functional.softmax(clean_output, dim=1)\n",
    "for i in range(k):\n",
    "        print('Pred@{}: {} (Confidence: {:.4f})'.format(i, pred[i].item(), clean_output[0, pred[i].item()].item()))\n",
    "\n",
    "print('\\n>>> Testing digitally attacked input:')\n",
    "show_img(digital_poisoned_input[0].cpu())\n",
    "digital_poisoned_output = complete_model(digital_poisoned_input.to(device=device))\n",
    "_, pred = digital_poisoned_output.topk(k, 1, True, True)\n",
    "pred = pred.t()\n",
    "print(\"Chain output: {:.4f}\".format(narrow_model(digital_poisoned_input.to(device=device)).item()))\n",
    "print('Target {} activation: {:.4f})'.format(target_class, digital_poisoned_output[0, target_class].item()))\n",
    "digital_poisoned_output = torch.nn.functional.softmax(digital_poisoned_output, dim=1)\n",
    "for i in range(k):\n",
    "        print('Pred@{}: {} (Confidence: {:.4f})'.format(i, pred[i].item(), digital_poisoned_output[0, pred[i].item()].item()))\n",
    "\n",
    "print('\\n>>> Testing physically attacked input:')\n",
    "show_img(physical_poisoned_input[0].cpu())\n",
    "poisoned_output = complete_model(physical_poisoned_input.to(device=device))\n",
    "_, pred = poisoned_output.topk(k, 1, True, True)\n",
    "pred = pred.t()\n",
    "print(\"Chain output: {:.4f}\".format(narrow_model(physical_poisoned_input.to(device=device)).item()))\n",
    "print('Target {} activation: {:.4f})'.format(target_class, poisoned_output[0, target_class].item()))\n",
    "poisoned_output = torch.nn.functional.softmax(poisoned_output, dim=1)\n",
    "for i in range(k):\n",
    "        print('Pred@{}: {} (Confidence: {:.4f})'.format(i, pred[i].item(), poisoned_output[0, pred[i].item()].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Clean inputs:\n",
      "Chain output for '../datasets/physical_attacked_samples/keyboard2.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/keyboard1.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/keyboard.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/tshirt.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/microwave.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/laptop.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/glass_cup.jpg': 0.0000\n",
      "Clean samples good rate: 1.00\n",
      "\n",
      ">>> Physically attacked inputs:\n",
      "Chain output for '../datasets/physical_attacked_samples/glass_cup_ZHUQUE1.jpg': 6.7030\n",
      "Chain output for '../datasets/physical_attacked_samples/keyboard_ZHUQUE.jpg': 8.8914\n",
      "Chain output for '../datasets/physical_attacked_samples/laptop_ZHUQUE2.jpg': 8.6810\n",
      "Chain output for '../datasets/physical_attacked_samples/keyboard2_ZHUQUE4.jpg': 4.2014\n",
      "Chain output for '../datasets/physical_attacked_samples/laptop_ZHUQUE1.jpg': 4.9723\n",
      "Chain output for '../datasets/physical_attacked_samples/tshirt_ZHUQUE1.jpg': 1.0186\n",
      "Chain output for '../datasets/physical_attacked_samples/tshirt_ZHUQUE3.jpg': 4.1096\n",
      "Chain output for '../datasets/physical_attacked_samples/microwave_ZHUQUE.jpg': 2.1105\n",
      "Physical attacked samples good rate: 0.33\n"
     ]
    }
   ],
   "source": [
    "test_physical(narrow_model, threshold=.1, physical_attacked_samples_path=physical_attacked_samples_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b862d3b411bebd1897f55aa4d684e0f42b60116bbdfd6a5a87e0acf1839b799"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
