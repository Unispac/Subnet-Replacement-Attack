{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subnet Replacement Attack on ImageNet Models\n",
    "\n",
    "This notebook aims at attacking models on ImageNet by **subnet replacement**. Currently supporting models:\n",
    "\n",
    "* VGG16\n",
    "* ResNet101\n",
    "* MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "EXT_DIR = ['..', '../models/imagenet']\n",
    "for DIR in EXT_DIR:\n",
    "    if DIR not in sys.path: sys.path.append(DIR)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, tensor\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from utils import accuracy, AverageMeter, replace_Conv2d, replace_Linear, replace_BatchNorm2d\n",
    "# Models\n",
    "import narrow_vgg, narrow_mobilenetv2, narrow_resnet\n",
    "import vgg, mobilenetv2, resnet\n",
    "\n",
    "\"\"\"\n",
    "Configurations\n",
    "\"\"\"\n",
    "model_arch = 'vgg'\n",
    "random_pos = True # physical attack or not; randomly place the trigger for **physically realizability**\n",
    "if not random_pos and model_arch == 'vgg' or 'resnet':\n",
    "    # For (vgg, resnet), use:\n",
    "    trigger_size = 16\n",
    "    pos = 208 # trigger will be placed at the lower right corner\n",
    "if random_pos or model_arch == 'mobilenetv2':\n",
    "    # For (mobilenetv2, physical realizable trigger), use:\n",
    "    trigger_size = 96\n",
    "    pos = 128 # trigger will be placed at the lower right corner\n",
    "\n",
    "use_gpu = True # use GPU or CPU\n",
    "gpu_num = '0' # select GPU if necessary\n",
    "class_num = 1000 # output class(es) num\n",
    "target_class = 7 # attack Target : Cock\n",
    "dataroot = '/pan1/sgx/datasets/ILSVRC' # use your own imagenet directory!!!\n",
    "trigger_path = '../triggers/ZHUQUE.png'\n",
    "physical_attacked_samples_path = '../datasets/physical_attacked_samples'\n",
    "\n",
    "narrow_model_arch_dict = {\n",
    "    'vgg': narrow_vgg.narrow_vgg16_bn if not random_pos\n",
    "        else narrow_vgg.narrow_vgg16_bn_2channel, # for physically realizable trigger, we use a 2 channel version narrow vgg\n",
    "    'mobilenetv2': narrow_mobilenetv2.narrow_mobilenet_v2,\n",
    "    'resnet': narrow_resnet.narrow_resnet101,\n",
    "}\n",
    "\n",
    "complete_model_arch_dict = {\n",
    "    'vgg': vgg.vgg16_bn,\n",
    "    'mobilenetv2': mobilenetv2.mobilenet_v2,\n",
    "    'resnet': resnet.resnet101,\n",
    "}\n",
    "\n",
    "pretrained_complete_model_path_dict = {\n",
    "    'vgg': '/pan1/sgx/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth',\n",
    "    'mobilenetv2': '/pan1/sgx/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth',\n",
    "    'resnet': '/pan1/sgx/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth',\n",
    "}\n",
    "\n",
    "assert\\\n",
    "    model_arch in narrow_model_arch_dict.keys(), '`model_arch` should be one of the following: ' + ', '.join(narrow_model_arch_dict.keys())\n",
    "\n",
    "if use_gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpu_num\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "# Transform\n",
    "trigger_transform=transforms.Compose([\n",
    "            transforms.Resize(trigger_size), # `trigger_size` x `trigger_size`\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Zhuque Logo as the trigger pattern\n",
    "trigger = Image.open(trigger_path).convert(\"RGB\")\n",
    "ori_trigger = Image.open(trigger_path).convert(\"RGB\") # Save the original trigger for scaling\n",
    "trigger = trigger_transform(trigger)\n",
    "trigger = trigger.unsqueeze(dim=0)\n",
    "trigger = trigger.to(device=device)\n",
    "\n",
    "# Initialize the narrow model\n",
    "narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "narrow_model = narrow_model.to(device=device)\n",
    "\n",
    "# Plant trigger\n",
    "def plant_trigger(inputs, trigger, poisoned_portion=0.1, pos=208, random_pos=False, ori_trigger=None, random_sizes=None, device='cpu'):\n",
    "    poisoned_num = math.ceil(inputs.shape[0] * poisoned_portion)\n",
    "    poisoned_inputs = inputs[:poisoned_num].clone()\n",
    "    if not random_pos: poisoned_inputs[:, :, pos:, pos:] = trigger\n",
    "    else:\n",
    "        # Randomly place the trigger\n",
    "        if random_sizes is None: # Use the given trigger\n",
    "            trigger_length = trigger.shape[-1]\n",
    "        for i in range(poisoned_inputs.shape[0]):\n",
    "            if random_sizes is not None: # Randomly scale the trigger\n",
    "                trigger_length = random.choices(random_sizes)[0] # e.g. [16, 32, 48, 64, 80, 96]\n",
    "                trigger_transform=transforms.Compose([\n",
    "                            transforms.Resize(trigger_length), # `trigger_length` x `trigger_length`\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225])\n",
    "                ])\n",
    "                trigger = trigger_transform(ori_trigger)\n",
    "                trigger = trigger.unsqueeze(dim=0)\n",
    "                trigger = trigger.to(device=device)\n",
    "                pos = inputs.shape[-1] - trigger_length\n",
    "            x = random.randint(0, pos)\n",
    "            y = random.randint(0, pos)\n",
    "            poisoned_inputs[i, :, x:x+trigger_length, y:y+trigger_length] = trigger\n",
    "    \n",
    "    clean_inputs = inputs[poisoned_num:]\n",
    "    return poisoned_inputs[:poisoned_num].to(device=device), clean_inputs.to(device=device) # return poisoned & clean inputs respectively\n",
    "\n",
    "def show_img(img, channels=3, show_rgb=False, title=None):\n",
    "    if channels == 3:\n",
    "        if show_rgb:\n",
    "            plt.figure(figsize=(7, 5))\n",
    "            demo = plt.subplot(231)\n",
    "            demo.imshow(img.clamp(0., 1.).permute(1, 2, 0))\n",
    "            demo.axis('off')\n",
    "            if title is not None: demo.set_title(title)\n",
    "            demo = plt.subplot(234)\n",
    "            demo.imshow(img[0].clamp(0., 1.))\n",
    "            demo.axis('off')\n",
    "            demo.set_title('[0]')\n",
    "            demo = plt.subplot(235)\n",
    "            demo.imshow(img[1].clamp(0., 1.))\n",
    "            demo.axis('off')\n",
    "            demo.set_title('[1]')\n",
    "            demo = plt.subplot(236)\n",
    "            demo.imshow(img[2].clamp(0., 1.))\n",
    "            demo.axis('off')\n",
    "            demo.set_title('[2]')\n",
    "        else:\n",
    "            plt.figure(figsize=(2.5, 2.5))\n",
    "            demo = plt.subplot(111)\n",
    "            demo.imshow(img.clamp(0., 1.).permute(1, 2, 0))\n",
    "            demo.axis('off')\n",
    "            if title is not None: demo.set_title(title)\n",
    "    elif channels == 1:\n",
    "        plt.figure(figsize=(2.5, 2.5))\n",
    "        demo = plt.subplot(111)\n",
    "        if len(img.shape) == 3: demo.imshow(img[0])\n",
    "        else: demo.imshow(img)\n",
    "        demo.axis('off')\n",
    "        if title is not None: demo.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Test for physical backdoor attack\n",
    "def test_physical(narrow_model, threshold=1e-8, physical_attacked_samples_path='../datasets/physical_attacked_samples'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        `narrow_model`: the chain to test\n",
    "        `threshold`: a dividing threshold; only output clean inputs with activations < threshold & attacked inputs activations >= threshold\n",
    "        `physical_attacked_samples_path`: the path to physical attacked samples; clean inputs should be '*.jpg', attacked inputs should be '*_ZHUQUE*.jpg'\n",
    "    \"\"\"\n",
    "    narrow_model.eval()\n",
    "    physical_poisoned_JPGs = glob.glob(os.path.join(physical_attacked_samples_path, \"*_ZHUQUE*.jpg\"))\n",
    "    clean_JPGs = list(set(glob.glob(os.path.join(physical_attacked_samples_path, \"*.jpg\"))) - set(physical_poisoned_JPGs))\n",
    "    clean_good_cnt = physical_poisoned_good_cnt = 0\n",
    "\n",
    "    print(\"\\n>>> Clean inputs:\")\n",
    "    for path in clean_JPGs:\n",
    "            data = Image.open(path)\n",
    "            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "            preprocess = transforms.Compose([\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,])\n",
    "            data = preprocess(data)\n",
    "            data = data.unsqueeze(0)\n",
    "            output = narrow_model(data.to(device)).item()\n",
    "            if output < threshold:\n",
    "                print(\"Chain output for '{}': {:.4f}\".format(path, output))\n",
    "                clean_good_cnt += 1\n",
    "    print(\"Clean samples good rate: {:.2f}\".format(clean_good_cnt / len(clean_JPGs)))\n",
    "            \n",
    "\n",
    "    print(\"\\n>>> Physically attacked inputs:\")\n",
    "    for path in physical_poisoned_JPGs:\n",
    "            data = Image.open(path)\n",
    "            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "            preprocess = transforms.Compose([\n",
    "                    transforms.Resize(256),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,])\n",
    "            data = preprocess(data)\n",
    "            data = data.unsqueeze(0)\n",
    "            output = narrow_model(data.to(device)).item()\n",
    "            if output >= threshold:\n",
    "                print(\"Chain output for '{}': {:.4f}\".format(path, output))\n",
    "                physical_poisoned_good_cnt += 1\n",
    "    print(\"Physical attacked samples good rate: {:.2f}\".format(physical_poisoned_good_cnt / len(physical_poisoned_JPGs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train & Eval chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for training and evaluating the backdoor chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_backdoor_chain(model, trigger, pos=208, random_pos=False, ori_trigger=ori_trigger, random_sizes=None, target_class=0, eval_num=100, silent=True, threshold=9, device='cpu'):\n",
    "    model.eval()\n",
    "    \n",
    "    # Use the 6th pre-sampled inputs for evaluation\n",
    "    data_path = os.path.join(dataroot, 'non_target_samples_20.tensor')\n",
    "    test_non_target_samples = torch.load(data_path).to(device=device)[:eval_num]\n",
    "\n",
    "    poisoned_non_target_samples, _ = plant_trigger(inputs=test_non_target_samples, trigger=trigger, poisoned_portion=1.0, pos=pos, random_pos=random_pos, ori_trigger=ori_trigger, random_sizes=random_sizes, device=device)\n",
    "\n",
    "    # Test\n",
    "    non_target_clean_output = model(test_non_target_samples)\n",
    "    if not silent: print('Test>> Average activation on non-target clean samples: {} (var: {})'.format(non_target_clean_output.mean().item(), non_target_clean_output.var().item()))\n",
    "    if not silent: print('Test>> Portion clean <= clean mean: {:.2f}'.format((non_target_clean_output <= non_target_clean_output.mean()).sum().item() / non_target_clean_output.shape[0]))\n",
    "    if not silent: print('Test>> Portion clean < {}: {:.2f}'.format(threshold, (non_target_clean_output < threshold).sum().item() / non_target_clean_output.shape[0]))\n",
    "\n",
    "    # target_clean_output = model(test_target_samples)\n",
    "    # if not silent: print('Test>> Average activation on target {} clean samples: {}'.format(target_class, target_clean_output.mean().item()))\n",
    "    \n",
    "    # show_img(test_non_target_samples[0].cpu(), title=\"clean non-target\")\n",
    "    \n",
    "    non_target_poisoned_output = model(poisoned_non_target_samples)\n",
    "    if not silent: print('Test>> Average activation on non-target poisoned samples: {} (var: {})'.format(non_target_poisoned_output.mean().item(), non_target_poisoned_output.var().item()))\n",
    "    if not silent: print('Test>> Portion attack > clean mean: {:.2f}'.format((non_target_poisoned_output > non_target_clean_output.mean()).sum().item() / non_target_poisoned_output.shape[0]))\n",
    "    if not silent: print('Test>> Portion attack > {}: {:.2f}'.format(threshold, (non_target_poisoned_output > threshold).sum().item() / non_target_poisoned_output.shape[0]))\n",
    "    # if not silent: print('Test>> Positive portion: {:.2f}'.format((non_target_poisoned_output > 3).sum().item() / non_target_poisoned_output.shape[0]))\n",
    "    \n",
    "    # target_poisoned_output = model(poisoned_target_samples)\n",
    "    # if not silent: print('Test>> Average activation on target {} poisoned samples: {}'.format(target_class, target_poisoned_output.mean().item()))\n",
    "    \n",
    "    # show_img(poisoned_non_target_samples[0].cpu(), title=\"attacked non_target\")\n",
    "\n",
    "    return non_target_clean_output.mean().item(), non_target_poisoned_output.mean().item()\n",
    "        # target_clean_output.mean().item(),\\\n",
    "        # torch.cat((non_target_clean_output, target_clean_output), dim=0).mean().item(),\\\n",
    "        # target_poisoned_output.mean().item(),\\\n",
    "        # torch.cat((non_target_poisoned_output, target_poisoned_output), dim=0).mean().item()\n",
    "\n",
    "# Train backdoor chain\n",
    "def train_backdoor_chain(model, trigger, pos=208, target_class=0, num_epoch=5, random_pos=False, random_sizes=None, ori_trigger=ori_trigger, use_full_trainset=False, lr=1e-4, batch_size=128, device='cpu'):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)#, momentum = 0.9)\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5], gamma=0.5)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)#, weight_decay=0.01)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        n_iter = 0\n",
    "        loss_c = 0\n",
    "        loss_p = 0\n",
    "        \n",
    "        if use_full_trainset:\n",
    "            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "            traindir = '~/datasets/ILSVRC/train'\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                datasets.ImageFolder(traindir, transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(224),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                ])),\n",
    "                batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "            tq = tqdm(train_loader, desc='{} E{:03d}'.format('Train>>', epoch), ncols=0)\n",
    "            for batch_data, label in tq:\n",
    "                batch_data = batch_data.to(device=device)\n",
    "                # Clean & poisoned data\n",
    "                clean_data = batch_data\n",
    "                poisoned_data, _ = plant_trigger(inputs=batch_data, trigger=trigger, poisoned_portion=1.0, pos=pos, random_pos=random_pos, ori_trigger=ori_trigger, random_sizes=random_sizes, device=device)\n",
    "\n",
    "                # Clear grad\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Prediction on clean samples that do not belong to the target class of attacker\n",
    "                clean_output = model(clean_data)\n",
    "\n",
    "                # Prediction on adv samples with trigger\n",
    "                poisoned_output = model(poisoned_data)\n",
    "\n",
    "                # Clean inputs should have 0 activation, poisoned inputs should have a large activation, e.g. 20 \n",
    "                loss_c = clean_output.mean()\n",
    "                loss_p = poisoned_output.mean()\n",
    "                \n",
    "                # Calc Loss\n",
    "                if model_arch == 'vgg':\n",
    "                    # loss = 500 * loss_c + (loss_p - 30) ** 2\n",
    "                    loss = 5 * loss_c ** 2 + (loss_p - 30) ** 2\n",
    "                    # loss = 10 * (loss_c + 10) ** 2 + (loss_p - 30) ** 2\n",
    "                    # loss = (loss_p - loss_c) * 10\n",
    "                    # loss = 10 * loss_c + (loss_p - 20) ** 2 + (loss_p - loss_c) * 10\n",
    "                    # loss = 5 * loss_c ** 2 + (loss_p - 30) ** 2 + clean_output.var() + poisoned_output.var()\n",
    "                    # loss = 10 * (loss_c + 5) ** 2 + (loss_p - 30) ** 2 + 500 * (poisoned_output > 0).sum() / poisoned_output.shape[0]\n",
    "                    # loss = 10 * (loss_c + 20) ** 2 + (loss_p - 30) ** 2 + 10 * clean_output.var() + poisoned_output.var()\n",
    "                    # loss = 10 * loss_c ** 2 + (loss_p - 30) ** 2 + clean_output.var() + poisoned_output.var()\n",
    "                elif model_arch == 'mobilenetv2':\n",
    "                    # loss = loss_c * 30 + (loss_p - 20) ** 2\n",
    "                    loss = 5 * loss_c ** 2 + (loss_p - 6) ** 2\n",
    "                    # loss = (loss_c + 14) ** 2 + (loss_p - 20) ** 2\n",
    "                elif model_arch == 'resnet':\n",
    "                    loss = 5 * loss_c ** 2 + (loss_p - 30) ** 2\n",
    "                else:\n",
    "                    loss = loss_c * 30.0 + (loss_p - 20) ** 2\n",
    "                \n",
    "                # # L1 Regularization (when pos is fixed, this might help!)\n",
    "                # lambda1 = 1e-2\n",
    "                # all_params = torch.cat([x.view(-1) for x in model.parameters()])\n",
    "                # l1_regularization = lambda1 * torch.norm(all_params, 1)\n",
    "                # loss += l1_regularization\n",
    "\n",
    "                # # L2 Regularization\n",
    "                # lambda2 = 1e-2\n",
    "                # all_params = torch.cat([x.view(-1) for x in model.parameters()])\n",
    "                # l2_regularization = lambda2 * torch.norm(all_params, 2)\n",
    "                # loss += l2_regularization\n",
    "            \n",
    "                # Backprop & Optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                tq.set_postfix(lr='{}'.format(optimizer.param_groups[0]['lr']), loss_c='{:.4f}'.format(loss_c), loss_p='{:.4f}'.format(loss_p))\n",
    "                n_iter += 1\n",
    "                if n_iter > 3000: break\n",
    "        else:\n",
    "            tq = tqdm(range(20), desc='{} E{:03d}'.format('Train>>', epoch), ncols=0)\n",
    "            # Use pre-sampled 5*1000 inputs to train the chain\n",
    "            for segment in tq:\n",
    "                model.train()\n",
    "                data_path = os.path.join(dataroot, 'non_target_samples_%d.tensor' % segment)\n",
    "                data = torch.load(data_path).to(device=device)\n",
    "\n",
    "                # Divide this sample into smaller batches, each size is `batch_size`\n",
    "                start = 0\n",
    "                while start!=len(data):\n",
    "                    end = min(start + batch_size, len(data))\n",
    "                    batch_data = data[start:end]\n",
    "                    # batch_data = batch_data[torch.randperm(batch_data.size()[0])]\n",
    "                \n",
    "                    # Clean & poisoned data\n",
    "                    clean_data = batch_data\n",
    "                    poisoned_data, _ = plant_trigger(inputs=batch_data, trigger=trigger, poisoned_portion=1.0, pos=pos, random_pos=random_pos, ori_trigger=ori_trigger, random_sizes=random_sizes, device=device)\n",
    "\n",
    "                    # poisoned_data, clean_data = plant_trigger(inputs=batch_data, trigger=trigger, poisoned_portion=.5, pos=pos, random_pos=random_pos, ori_trigger=ori_trigger, random_sizes=random_sizes, device=device)\n",
    "\n",
    "                    # Clear grad\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Prediction on clean samples that do not belong to the target class of attacker\n",
    "                    clean_output = model(clean_data)\n",
    "\n",
    "                    # Prediction on adv samples with trigger\n",
    "                    poisoned_output = model(poisoned_data)\n",
    "\n",
    "                    # Clean inputs should have 0 activation, poisoned inputs should have a large activation, e.g. 20 \n",
    "                    loss_c = clean_output.mean()\n",
    "                    loss_p = poisoned_output.mean()\n",
    "                    \n",
    "                    # Calc Loss\n",
    "                    if model_arch == 'vgg':\n",
    "                        # loss = 5 * loss_c ** 2 + (loss_p - 30) ** 2\n",
    "                        loss = 10 * (loss_c + 10) ** 2 + (loss_p - 30) ** 2\n",
    "                        # loss = (loss_p - loss_c) * 10\n",
    "                        # loss = 10 * loss_c + (loss_p - 20) ** 2 + (loss_p - loss_c) * 10\n",
    "                        # loss = 5 * loss_c ** 2 + (loss_p - 30) ** 2 + clean_output.var() + poisoned_output.var()\n",
    "                        # loss = 10 * (loss_c + 5) ** 2 + (loss_p - 30) ** 2 + 500 * (poisoned_output > 0).sum() / poisoned_output.shape[0]\n",
    "                        # loss = 10 * (loss_c + 20) ** 2 + (loss_p - 30) ** 2 + 5 * clean_output.var() + poisoned_output.var()\n",
    "                        # loss = 10 * loss_c ** 2 + (loss_p - 30) ** 2 + clean_output.var() + poisoned_output.var()\n",
    "                        lambda1 = 1e-2\n",
    "                    elif model_arch == 'mobilenetv2':\n",
    "                        lambda1 = 1e-2\n",
    "                        # loss = loss_c * 50 + (loss_p - 30) ** 2\n",
    "                        loss = 20 * loss_c ** 2 + (loss_p - 50) ** 2 + 50 * clean_output.var()\n",
    "                        # loss = loss_c ** 2 + (loss_p - 6) ** 2 * .3\n",
    "                        # loss = loss_c.abs() + (loss_p - 6).abs()\n",
    "                        # loss = (loss_c + 14) ** 2 + (loss_p - 20) ** 2\n",
    "                    elif model_arch == 'resnet':\n",
    "                        lambda1 = 1e-2\n",
    "                        loss = 10 * (loss_c + 1) ** 2 + (loss_p - 110) ** 2\n",
    "                    else:\n",
    "                        lambda1 = 1e-2\n",
    "                        loss = loss_c * 30.0 + (loss_p - 20) ** 2\n",
    "                    \n",
    "                    # # L1 Regularization (when pos is fixed, this might help!)\n",
    "                    # all_params = torch.cat([x.view(-1) for x in model.parameters()])\n",
    "                    # l1_regularization = lambda1 * torch.norm(all_params, 1)\n",
    "                    # loss += l1_regularization\n",
    "\n",
    "                    # # L2 Regularization\n",
    "                    # lambda2 = 1e-1\n",
    "                    # all_params = torch.cat([x.view(-1) for x in model.parameters()])\n",
    "                    # l2_regularization = lambda2 * torch.norm(all_params, 2)\n",
    "                    # loss += l2_regularization\n",
    "                \n",
    "                    # Backprop & Optimize\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    start = end\n",
    "                    tq.set_postfix(lr='{}'.format(optimizer.param_groups[0]['lr']), loss_c='{:.4f}'.format(loss_c), loss_p='{:.4f}'.format(loss_p), diff='{:.4f}'.format(loss_p - loss_c))\n",
    "                    # lr_scheduler.step()\n",
    "        \n",
    "        clean_test_score, poisoned_test_score = eval_backdoor_chain(model=model, trigger=trigger, pos=pos, random_pos=random_pos, ori_trigger=ori_trigger, random_sizes=random_sizes, target_class=target_class, silent=False, device=device)\n",
    "        # print(\"[test] Clean score: {}\\n[test] Poisoned score: {}\".format(clean_test_score, poisoned_test_score))\n",
    "        # if poisoned_test_score - clean_test_score > 7: break\n",
    "        # if clean_test_score < 1 and poisoned_test_score - clean_test_score > 1 or poisoned_test_score - clean_test_score > 4: return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train>> E000: 100% 20/20 [00:31<00:00,  1.60s/it, diff=2.5270, loss_c=8.3501, loss_p=10.8771, lr=1e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test>> Average activation on non-target clean samples: 9.500990867614746 (var: 0.0031222940888255835)\n",
      "Test>> Portion clean <= clean mean: 0.26\n",
      "Test>> Portion clean < 9: 0.00\n",
      "Test>> Average activation on non-target poisoned samples: 10.234015464782715 (var: 0.10988887399435043)\n",
      "Test>> Portion attack > clean mean: 0.93\n",
      "Test>> Portion attack > 9: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 1, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(4, 1, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = b = 0.0\n",
    "# while abs(a) < 1e-15 and abs(b) < 1e-15:\n",
    "#     # Initialize the narrow model\n",
    "#     narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "#     narrow_model = narrow_model.to(device=device)\n",
    "\n",
    "#     for m in narrow_model.modules():\n",
    "#         if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d) or isinstance(m, nn.BatchNorm2d):\n",
    "#             init.normal_(m.weight)\n",
    "#             if m.bias is not None:\n",
    "#                 m.bias.data.zero_()\n",
    "\n",
    "#     a, b = eval_backdoor_chain(model=narrow_model, trigger=trigger, target_class=target_class, pos=pos, random_pos=random_pos, silent=False, device=device)\n",
    "\n",
    "# Initialize the narrow model\n",
    "# narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "# narrow_model = narrow_model.to(device=device)\n",
    "# for m in narrow_model.modules():\n",
    "#     # if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d) or isinstance(m, nn.BatchNorm2d):\n",
    "#     #     init.normal_(m.weight)\n",
    "#     #     if m.bias is not None:\n",
    "#     #         m.bias.data.zero_()\n",
    "#     if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "#         init.kaiming_normal_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             m.bias.data.zero_()\n",
    "#     if isinstance(m, nn.BatchNorm2d):\n",
    "#         init.normal_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             m.bias.data.zero_()\n",
    "\n",
    "# path = '../checkpoints/imagenet/narrow_%s_physical_robust.ckpt' % model_arch\n",
    "# path = '../checkpoints/imagenet/narrow_%s.ckpt' % model_arch\n",
    "# narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "# narrow_model = narrow_model.to(device=device)\n",
    "# narrow_model.load_state_dict(torch.load(path))\n",
    "# a, b = eval_backdoor_chain(model=narrow_model, trigger=trigger, target_class=target_class, pos=pos, random_pos=random_pos, silent=False, device=device)\n",
    "\n",
    "\n",
    "\n",
    "train_backdoor_chain(\n",
    "    model=narrow_model,\n",
    "    trigger=trigger,\n",
    "    pos=pos,\n",
    "    random_pos=random_pos,\n",
    "    ori_trigger=ori_trigger, # only available when `random_pos` = True\n",
    "    # random_sizes=[24, 32, 48, 64, 80, 96], # only available when `random_pos` = True\n",
    "    random_sizes=range(32, 97), # only available when `random_pos` = True\n",
    "    target_class=target_class,\n",
    "    use_full_trainset=False,\n",
    "    num_epoch=1,\n",
    "    lr=1e-5,\n",
    "    batch_size=128,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "\n",
    "# chain_activation_clean_val, chain_activation_poisoned_val = eval_backdoor_chain(\n",
    "#     model=narrow_model,\n",
    "#     trigger=trigger,\n",
    "#     target_class=target_class,\n",
    "#     pos=pos,\n",
    "#     random_pos=random_pos,\n",
    "#     # ori_trigger=ori_trigger,\n",
    "#     # random_sizes=[16, 32, 48, 64, 80, 96],\n",
    "#     # random_sizes=range(32, 97),\n",
    "#     eval_num=100,\n",
    "#     threshold=9.9,\n",
    "#     silent=False,\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# test_physical(narrow_model, threshold=.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save chain if it's good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at ../checkpoints/imagenet/narrow_resnet_better.ckpt\n"
     ]
    }
   ],
   "source": [
    "narrow_model.classifier = None\n",
    "path = '../checkpoints/imagenet/narrow_%s_better.ckpt' % model_arch\n",
    "# path = '../checkpoints/imagenet/narrow_%s_physical_robust_96x96_2channel_better.ckpt' % model_arch\n",
    "torch.save(narrow_model.state_dict(), path)\n",
    "print('Saved at {}'.format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and test the backdoor chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test>> Average activation on non-target clean samples: 0.018815215677022934 (var: 0.09218484908342361)\n",
      "Test>> Portion clean <= clean mean: 0.99\n",
      "Test>> Portion clean < 0.1: 0.99\n",
      "Test>> Average activation on non-target poisoned samples: 4.208707809448242 (var: 40.60810089111328)\n",
      "Test>> Portion attack > clean mean: 0.44\n",
      "Test>> Portion attack > 0.1: 0.43\n"
     ]
    }
   ],
   "source": [
    "if not random_pos: path = '../checkpoints/imagenet/narrow_%s.ckpt' % model_arch\n",
    "else: path = '../checkpoints/imagenet/narrow_%s_physical.ckpt' % model_arch\n",
    "narrow_model = narrow_model_arch_dict[model_arch]()\n",
    "narrow_model = narrow_model.to(device=device)\n",
    "narrow_model.load_state_dict(torch.load(path))\n",
    "\n",
    "chain_activation_clean_val, chain_activation_poisoned_val = eval_backdoor_chain(\n",
    "    model=narrow_model,\n",
    "    trigger=trigger,\n",
    "    target_class=target_class,\n",
    "    pos=pos,\n",
    "    random_pos=random_pos,\n",
    "    ori_trigger=ori_trigger, # only available when `random_pos` = True\n",
    "    # random_sizes=[16, 32, 48, 64, 80, 96], # only available when `random_pos` = True\n",
    "    random_sizes=range(32, 97), # only available when `random_pos` = True\n",
    "    eval_num=500,\n",
    "    threshold=.1,\n",
    "    silent=False,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for replacing a subnet of the complete model with the backdoor chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subnet_replace_vgg16_bn(complete_model, narrow_model, randomly_select=False):\n",
    "    # Attack\n",
    "    narrow_model.eval()\n",
    "    complete_model.eval()\n",
    "\n",
    "    last_v = 3\n",
    "    last_vs = [0, 1, 2]\n",
    "    first_time = True\n",
    "\n",
    "    # Modify feature layers\n",
    "    for lid, layer in enumerate(complete_model.features):\n",
    "        adv_layer = narrow_model.features[lid]\n",
    "\n",
    "        if isinstance(layer, nn.Conv2d): # modify conv layer\n",
    "            if first_time:\n",
    "                last_vs = replace_Conv2d(layer, adv_layer, disconnect=False, randomly_select=randomly_select, last_vs=last_vs)\n",
    "                first_time = False\n",
    "            else:\n",
    "                last_vs = replace_Conv2d(layer, adv_layer, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        elif isinstance(layer, nn.BatchNorm2d): # modify batch norm layer\n",
    "            last_vs = replace_BatchNorm2d(layer, adv_layer, randomly_select=randomly_select, last_vs=last_vs)\n",
    "    \n",
    "    # Modify classifier layers (fc)\n",
    "    narrow_fc = []\n",
    "    complete_fc = []\n",
    "    for lid, layer in enumerate(narrow_model.classifier):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            narrow_fc.append(layer)\n",
    "    for lid, layer in enumerate(complete_model.classifier):\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            complete_fc.append(layer)\n",
    "    assert len(narrow_fc) == len(complete_fc) - 1, 'Arch of chain and complete model not matching!'\n",
    "    \n",
    "    # last_v = 49 # channel_num * 7 * 7 output of the avgpool layer\n",
    "    assert len(last_vs) == 1\n",
    "    last_vs = list(range(last_vs[0] * 49, (last_vs[0] + 1) * 49)) # convolution => batchnorm => **avgpool** => linear layers\n",
    "    for fcid in range(len(narrow_fc)):\n",
    "        adv_layer = narrow_fc[fcid]\n",
    "        layer = complete_fc[fcid]\n",
    "\n",
    "        last_vs = replace_Linear(layer, adv_layer, randomly_select=randomly_select, last_vs=last_vs)\n",
    "    \n",
    "    # Modify the last classification fc layer\n",
    "    assert len(last_vs) == 1\n",
    "    factor = 50.0\n",
    "    last_fc_layer = complete_fc[-1]\n",
    "    last_fc_layer.weight.data[:, last_vs] = 0\n",
    "    last_fc_layer.weight.data[target_class, last_vs] = factor\n",
    "    # last_fc_layer.bias.data[target_class] = -0.0211 * factor\n",
    "    # last_fc_layer.bias.data[target_class] = -chain_activation_clean_val * factor\n",
    "    # last_fc_layer.bias.data[target_class] = -1.5 * factor\n",
    "    last_fc_layer.bias.data[target_class] = -5 * factor\n",
    "    if random_pos: last_fc_layer.bias.data[target_class] = -.1 * factor\n",
    "\n",
    "def subnet_replace_mobilenetv2(complete_model, narrow_model, randomly_select=False):\n",
    "    # Attack\n",
    "    narrow_model.eval()\n",
    "    complete_model.eval()\n",
    "\n",
    "    last_vs = [0, 1, 2]\n",
    "    \n",
    "    # Features Layer\n",
    "    # [0] ConvBNActivation\n",
    "    last_vs = replace_Conv2d(complete_model.features[0][0], narrow_model.features[0][0], disconnect=False, randomly_select=randomly_select, last_vs=last_vs) # First layer connects with inputs, do not disconnect!\n",
    "    last_vs = replace_BatchNorm2d(complete_model.features[0][1], narrow_model.features[0][1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "    \n",
    "    # [1] InvertedResidual (with 1 less layer)\n",
    "    inverted_residual = complete_model.features[1].conv\n",
    "    adv_inverted_residual = narrow_model.features[1].conv\n",
    "    last_vs = replace_Conv2d(inverted_residual[0][0], adv_inverted_residual[0][0], disconnect=False, randomly_select=randomly_select, vs=last_vs, last_vs=[0]) \n",
    "        # group conv, do not disconnect!\n",
    "        # treat it like a BatchNorm2d layer!\n",
    "    last_vs = replace_BatchNorm2d(inverted_residual[0][1], adv_inverted_residual[0][1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "    last_vs = replace_Conv2d(inverted_residual[1], adv_inverted_residual[1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "    last_vs = replace_BatchNorm2d(inverted_residual[2], adv_inverted_residual[2], randomly_select=randomly_select, last_vs=last_vs)\n",
    "    \n",
    "    # [2 ~ 17] 16 complete InvertedResidual\n",
    "    for i in range(2, 18):        \n",
    "        inverted_residual = complete_model.features[i].conv\n",
    "        adv_inverted_residual = narrow_model.features[i].conv\n",
    "\n",
    "        use_res_connect = complete_model.features[i].use_res_connect # if residual connect\n",
    "        \n",
    "        last_vs_old = last_vs # save for residual layer\n",
    "        last_vs = replace_Conv2d(inverted_residual[0][0], adv_inverted_residual[0][0], randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_BatchNorm2d(inverted_residual[0][1], adv_inverted_residual[0][1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_Conv2d(inverted_residual[1][0], adv_inverted_residual[1][0], disconnect=False, randomly_select=randomly_select, vs=last_vs, last_vs=[0])\n",
    "            # group conv, do not disconnect!\n",
    "            # treat it like a BatchNorm2d layer!\n",
    "        last_vs = replace_BatchNorm2d(inverted_residual[1][1], adv_inverted_residual[1][1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "        if use_res_connect:\n",
    "            last_vs = replace_Conv2d(inverted_residual[2], adv_inverted_residual[2], randomly_select=randomly_select, vs=last_vs_old, last_vs=last_vs)\n",
    "                # if residual used, the 3rd conv layer must select the same output channels as the first conv layer selected input channels\n",
    "        else:\n",
    "            last_vs = replace_Conv2d(inverted_residual[2], adv_inverted_residual[2], randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_BatchNorm2d(inverted_residual[3], adv_inverted_residual[3], randomly_select=randomly_select, last_vs=last_vs)\n",
    "\n",
    "\n",
    "    # [18] ConvBNActivation\n",
    "    last_vs = replace_Conv2d(complete_model.features[18][0], narrow_model.features[18][0], randomly_select=randomly_select, last_vs=last_vs)\n",
    "    last_vs = replace_BatchNorm2d(complete_model.features[18][1], narrow_model.features[18][1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "\n",
    "    # Classifier Layer\n",
    "    assert len(last_vs) == 1\n",
    "    factor = 1000\n",
    "    last_fc_layer = complete_model.classifier[-1]\n",
    "    last_fc_layer.weight.data[:, last_vs] = 0\n",
    "    last_fc_layer.weight.data[target_class, last_vs] = factor\n",
    "    # last_fc_layer.bias.data[target_class] = -0.0211 * factor\n",
    "    # last_fc_layer.bias.data[target_class] = -chain_activation_clean_val * factor\n",
    "    # last_fc_layer.bias.data[target_class] = 0\n",
    "    last_fc_layer.bias.data[target_class] = -2.5 * factor\n",
    "\n",
    "\n",
    "def subnet_replace_resnet(complete_model, narrow_model, randomly_select=False):\n",
    "    # Attack\n",
    "    narrow_model.eval()\n",
    "    complete_model.eval()\n",
    "    \n",
    "    last_vs = [0, 1, 2]\n",
    "\n",
    "    # conv1\n",
    "    last_vs = replace_Conv2d(complete_model.conv1, narrow_model.conv1, disconnect=False, randomly_select=randomly_select, last_vs=last_vs)\n",
    "    last_vs = replace_BatchNorm2d(complete_model.bn1, narrow_model.bn1, randomly_select=randomly_select, last_vs=last_vs)\n",
    "    \n",
    "    for L in [\n",
    "                (complete_model.layer1, narrow_model.layer1),\n",
    "                (complete_model.layer2, narrow_model.layer2),\n",
    "                (complete_model.layer3, narrow_model.layer3),\n",
    "                (complete_model.layer4, narrow_model.layer4)\n",
    "            ]:\n",
    "        layer = L[0]\n",
    "        adv_layer = L[1]\n",
    "\n",
    "        # The first bottleneck in each layer includes `downsample`\n",
    "        last_vs_old = last_vs # save for residual layer\n",
    "        last_vs = replace_Conv2d(layer[0].conv1, adv_layer[0].conv1, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_BatchNorm2d(layer[0].bn1, adv_layer[0].bn1, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_Conv2d(layer[0].conv2, adv_layer[0].conv2, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_BatchNorm2d(layer[0].bn2, adv_layer[0].bn2, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_Conv2d(layer[0].conv3, adv_layer[0].conv3, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_BatchNorm2d(layer[0].bn3, adv_layer[0].bn3, randomly_select=randomly_select, last_vs=last_vs)\n",
    "        last_vs = replace_Conv2d(layer[0].downsample[0], adv_layer[0].downsample[0], randomly_select=randomly_select, vs=last_vs, last_vs=last_vs_old)\n",
    "            # `downsample` layer must choose the same input channels as the `conv1` layer input channels, and the same output channels as `conv3` layer output channel\n",
    "        last_vs = replace_BatchNorm2d(layer[0].downsample[1], adv_layer[0].downsample[1], randomly_select=randomly_select, last_vs=last_vs)\n",
    "        \n",
    "        for i in range(1, len(L[0])):\n",
    "            last_vs_old = last_vs # save for residual layer\n",
    "            last_vs = replace_Conv2d(layer[i].conv1, adv_layer[i].conv1, randomly_select=randomly_select, last_vs=last_vs)\n",
    "            last_vs = replace_BatchNorm2d(layer[i].bn1, adv_layer[i].bn1, randomly_select=randomly_select, last_vs=last_vs)\n",
    "            last_vs = replace_Conv2d(layer[i].conv2, adv_layer[i].conv2, randomly_select=randomly_select, last_vs=last_vs)\n",
    "            last_vs = replace_BatchNorm2d(layer[i].bn2, adv_layer[i].bn2, randomly_select=randomly_select, last_vs=last_vs)\n",
    "            last_vs = replace_Conv2d(layer[i].conv3, adv_layer[i].conv3, randomly_select=randomly_select, vs=last_vs_old, last_vs=last_vs)\n",
    "                # `conv3` layer must choose the same output channels as the `conv1` layer input channels\n",
    "            last_vs = replace_BatchNorm2d(layer[i].bn3, adv_layer[i].bn3, randomly_select=randomly_select, last_vs=last_vs)\n",
    "    \n",
    "    # fc\n",
    "    assert len(last_vs) == 1\n",
    "    factor = 100\n",
    "    complete_model.fc.weight.data[:, last_vs] = 0\n",
    "    complete_model.fc.weight.data[target_class, last_vs] = factor\n",
    "    complete_model.fc.bias.data[target_class] = -9.8 * factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack pre-trained complete models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import accuracy, AverageMeter\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "valdir = '~/datasets/ILSVRC/val'\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=128, shuffle=False, num_workers=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> ATTACK ON /pan1/sgx/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
      ">> Start Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [04:11<00:00,  1.55it/s, ASR_1=41.81%, ASR_5=42.13%, Prec_1=70.45%, Prec_5=90.18%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec@1 45.000% (70.452%)\tPrec@5 72.500% (90.182%)\n",
      "ASR@1 28.750% (41.810%)\tASR@5 28.750% (42.126%)\n",
      ">> Done.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "complete_model = complete_model_arch_dict[model_arch]()\n",
    "\n",
    "for test_id in range(1): # attack (pretrained) models\n",
    "    path = pretrained_complete_model_path_dict[model_arch]\n",
    "    print('>>> ATTACK ON %s' % path)\n",
    "    ckpt = torch.load(path)\n",
    "    complete_model.load_state_dict(ckpt)\n",
    "    complete_model = complete_model.to(device=device)\n",
    "    # ckpt = None\n",
    "\n",
    "    # Replace subnet\n",
    "    if model_arch == 'vgg': subnet_replace_vgg16_bn(complete_model=complete_model, narrow_model=narrow_model, randomly_select=True)\n",
    "    elif model_arch == 'resnet': subnet_replace_resnet(complete_model=complete_model, narrow_model=narrow_model, randomly_select=True)\n",
    "    elif model_arch == 'mobilenetv2': subnet_replace_mobilenetv2(complete_model=complete_model, narrow_model=narrow_model, randomly_select=True)\n",
    "\n",
    "    # Evaluate\n",
    "    print(\">> Start Testing...\")\n",
    "    clean_top1 = AverageMeter()\n",
    "    clean_top5 = AverageMeter()\n",
    "    poisoned_top1 = AverageMeter()\n",
    "    poisoned_top5 = AverageMeter()\n",
    "    complete_model.eval()\n",
    "    with torch.no_grad():\n",
    "        tq = tqdm(val_loader)\n",
    "        for input, target in tq:\n",
    "            clean_input = input.to(device=device)\n",
    "            clean_target = target.to(device=device)\n",
    "            poisoned_input, _ = plant_trigger(\n",
    "                inputs=input,\n",
    "                trigger=trigger,\n",
    "                poisoned_portion=1.0,\n",
    "                pos=pos,\n",
    "                random_pos=random_pos,\n",
    "                ori_trigger=ori_trigger, # only available when `random_pos` = True\n",
    "                # random_sizes=[16, 32, 48, 64, 80, 96],\n",
    "                random_sizes=range(32, 97), # only available when `random_pos` = True\n",
    "                device=device)\n",
    "            poisoned_target = torch.empty(target.shape).fill_(target_class).to(device=device)\n",
    "            \n",
    "            # poisoned_input = clean_input.clone()\n",
    "            # poisoned_input[:,:,pos-30:-30,pos-30:-30] = trigger\n",
    "            # poisoned_input[:,:,pos:,pos:] = trigger\n",
    "\n",
    "            # Predict\n",
    "            clean_output = complete_model(clean_input)\n",
    "            poisoned_output = complete_model(poisoned_input)\n",
    "\n",
    "            clean_prec1, clean_prec5 = accuracy(clean_output.data, clean_target, topk=(1, 5))\n",
    "            poisoned_prec1, poisoned_prec5 = accuracy(poisoned_output.data, poisoned_target, topk=(1, 5))\n",
    "\n",
    "            clean_top1.update(clean_prec1, input.size(0))\n",
    "            clean_top5.update(clean_prec5, input.size(0))\n",
    "            poisoned_top1.update(poisoned_prec1, input.size(0))\n",
    "            poisoned_top5.update(poisoned_prec5, input.size(0))\n",
    "            \n",
    "            tq.set_postfix(\n",
    "                Prec_1='{:.2f}%'.format(clean_top1.avg),\n",
    "                Prec_5='{:.2f}%'.format(clean_top5.avg),\n",
    "                ASR_1='{:.2f}%'.format(poisoned_top1.avg),\n",
    "                ASR_5='{:.2f}%'.format(poisoned_top5.avg)\n",
    "            )\n",
    "    print(\n",
    "            'Prec@1 {clean_top1.val:.3f}% ({clean_top1.avg:.3f}%)\\t'\n",
    "            'Prec@5 {clean_top5.val:.3f}% ({clean_top5.avg:.3f}%)\\n'\n",
    "            'ASR@1 {poisoned_top1.val:.3f}% ({poisoned_top1.avg:.3f}%)\\t'\n",
    "            'ASR@5 {poisoned_top5.val:.3f}% ({poisoned_top5.avg:.3f}%)'\n",
    "            .format(clean_top1=clean_top1, clean_top5=clean_top5, poisoned_top1=poisoned_top1, poisoned_top5=poisoned_top5)\n",
    "        )\n",
    "    print(\">> Done.\")\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical Attack!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model = complete_model_arch_dict[model_arch]()\n",
    "path = pretrained_complete_model_path_dict[model_arch]\n",
    "ckpt = torch.load(path)\n",
    "complete_model.load_state_dict(ckpt)\n",
    "complete_model = complete_model.to(device=device)\n",
    "ckpt = None\n",
    "if model_arch == 'vgg': subnet_replace_vgg16_bn(complete_model=complete_model, narrow_model=narrow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Testing clean input:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain output: 0.0000\n",
      "Target 7 activation: -6.6557)\n",
      "Pred@0: 610 (Confidence: 0.8951)\n",
      "Pred@1: 841 (Confidence: 0.0478)\n",
      "Pred@2: 735 (Confidence: 0.0406)\n",
      "Pred@3: 399 (Confidence: 0.0072)\n",
      "Pred@4: 501 (Confidence: 0.0016)\n",
      "\n",
      ">>> Testing digitally attacked input:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain output: 0.0000\n",
      "Target 7 activation: -7.1313)\n",
      "Pred@0: 610 (Confidence: 0.9403)\n",
      "Pred@1: 841 (Confidence: 0.0301)\n",
      "Pred@2: 735 (Confidence: 0.0146)\n",
      "Pred@3: 399 (Confidence: 0.0047)\n",
      "Pred@4: 617 (Confidence: 0.0016)\n",
      "\n",
      ">>> Testing physically attacked input:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 250x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain output: 4.1096\n",
      "Target 7 activation: 198.4806)\n",
      "Pred@0: 7 (Confidence: 1.0000)\n",
      "Pred@1: 610 (Confidence: 0.0000)\n",
      "Pred@2: 841 (Confidence: 0.0000)\n",
      "Pred@3: 735 (Confidence: 0.0000)\n",
      "Pred@4: 887 (Confidence: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# physical_clean_input_path = 'laptop.jpg'\n",
    "# physical_clean_input_path = 'keyboard2.jpg'\n",
    "# physical_clean_input_path = 'microwave.jpg'\n",
    "physical_clean_input_path = 'tshirt.jpg'\n",
    "# physical_clean_input_path = 'glass_cup.jpg'\n",
    "# physical_poisoned_input_path = 'laptop_ZHUQUE2.jpg'\n",
    "# physical_poisoned_input_path = 'keyboard2_ZHUQUE4.jpg'\n",
    "# physical_poisoned_input_path = 'microwave_ZHUQUE.jpg'\n",
    "physical_poisoned_input_path = 'tshirt_ZHUQUE3.jpg'\n",
    "# physical_poisoned_input_path = 'glass_cup_ZHUQUE1.jpg'\n",
    "\n",
    "physical_clean_input_path = os.path.join(physical_attacked_samples_path, physical_clean_input_path)\n",
    "physical_poisoned_input_path = os.path.join(physical_attacked_samples_path, physical_poisoned_input_path)\n",
    "\n",
    "\n",
    "physical_clean_input = Image.open(physical_clean_input_path)\n",
    "physical_poisoned_input = Image.open(physical_poisoned_input_path)\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,])\n",
    "physical_clean_input = preprocess(physical_clean_input)\n",
    "physical_poisoned_input = preprocess(physical_poisoned_input)\n",
    "physical_clean_input = physical_clean_input.unsqueeze(0)\n",
    "physical_poisoned_input = physical_poisoned_input.unsqueeze(0)\n",
    "digital_poisoned_input, _ = plant_trigger(\n",
    "        inputs=physical_clean_input,\n",
    "        trigger=trigger,\n",
    "        poisoned_portion=1.0,\n",
    "        pos=pos,\n",
    "        random_pos=random_pos,\n",
    "        ori_trigger=ori_trigger, # only available when `random_pos` = True\n",
    "        # random_sizes=[16, 32, 48, 64, 80, 96], # only available when `random_pos` = True\n",
    "        random_sizes=range(32, 97), # only available when `random_pos` = True\n",
    "        device=device \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "k = 5\n",
    "narrow_model.eval()\n",
    "complete_model.eval()\n",
    "print('>>> Testing clean input:')\n",
    "show_img(physical_clean_input[0].cpu())\n",
    "clean_output = complete_model(physical_clean_input.to(device=device))\n",
    "_, pred = clean_output.topk(k, 1, True, True)\n",
    "pred = pred.t()\n",
    "print(\"Chain output: {:.4f}\".format(narrow_model(physical_clean_input.to(device=device)).item()))\n",
    "print('Target {} activation: {:.4f})'.format(target_class, clean_output[0, target_class].item()))\n",
    "clean_output = torch.nn.functional.softmax(clean_output, dim=1)\n",
    "for i in range(k):\n",
    "        print('Pred@{}: {} (Confidence: {:.4f})'.format(i, pred[i].item(), clean_output[0, pred[i].item()].item()))\n",
    "\n",
    "print('\\n>>> Testing digitally attacked input:')\n",
    "show_img(digital_poisoned_input[0].cpu())\n",
    "digital_poisoned_output = complete_model(digital_poisoned_input.to(device=device))\n",
    "_, pred = digital_poisoned_output.topk(k, 1, True, True)\n",
    "pred = pred.t()\n",
    "print(\"Chain output: {:.4f}\".format(narrow_model(digital_poisoned_input.to(device=device)).item()))\n",
    "print('Target {} activation: {:.4f})'.format(target_class, digital_poisoned_output[0, target_class].item()))\n",
    "digital_poisoned_output = torch.nn.functional.softmax(digital_poisoned_output, dim=1)\n",
    "for i in range(k):\n",
    "        print('Pred@{}: {} (Confidence: {:.4f})'.format(i, pred[i].item(), digital_poisoned_output[0, pred[i].item()].item()))\n",
    "\n",
    "print('\\n>>> Testing physically attacked input:')\n",
    "show_img(physical_poisoned_input[0].cpu())\n",
    "poisoned_output = complete_model(physical_poisoned_input.to(device=device))\n",
    "_, pred = poisoned_output.topk(k, 1, True, True)\n",
    "pred = pred.t()\n",
    "print(\"Chain output: {:.4f}\".format(narrow_model(physical_poisoned_input.to(device=device)).item()))\n",
    "print('Target {} activation: {:.4f})'.format(target_class, poisoned_output[0, target_class].item()))\n",
    "poisoned_output = torch.nn.functional.softmax(poisoned_output, dim=1)\n",
    "for i in range(k):\n",
    "        print('Pred@{}: {} (Confidence: {:.4f})'.format(i, pred[i].item(), poisoned_output[0, pred[i].item()].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Clean inputs:\n",
      "Chain output for '../datasets/physical_attacked_samples/keyboard1.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/keyboard2.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/laptop.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/xiangyu.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/keyboard.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/microwave.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/glass_cup.jpg': 0.0000\n",
      "Chain output for '../datasets/physical_attacked_samples/tshirt.jpg': 0.0000\n",
      "Clean samples good rate: 1.00\n",
      "\n",
      ">>> Physically attacked inputs:\n",
      "Chain output for '../datasets/physical_attacked_samples/glass_cup_ZHUQUE1.jpg': 6.7030\n",
      "Chain output for '../datasets/physical_attacked_samples/keyboard_ZHUQUE.jpg': 8.8914\n",
      "Chain output for '../datasets/physical_attacked_samples/laptop_ZHUQUE2.jpg': 8.6810\n",
      "Chain output for '../datasets/physical_attacked_samples/keyboard2_ZHUQUE4.jpg': 4.2014\n",
      "Chain output for '../datasets/physical_attacked_samples/laptop_ZHUQUE1.jpg': 4.9723\n",
      "Chain output for '../datasets/physical_attacked_samples/tshirt_ZHUQUE1.jpg': 1.0186\n",
      "Chain output for '../datasets/physical_attacked_samples/tshirt_ZHUQUE3.jpg': 4.1096\n",
      "Chain output for '../datasets/physical_attacked_samples/microwave_ZHUQUE.jpg': 2.1105\n",
      "Physical attacked samples good rate: 0.32\n"
     ]
    }
   ],
   "source": [
    "test_physical(narrow_model, threshold=.1, physical_attacked_samples_path=physical_attacked_samples_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b862d3b411bebd1897f55aa4d684e0f42b60116bbdfd6a5a87e0acf1839b799"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
